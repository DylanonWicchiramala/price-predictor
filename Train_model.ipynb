{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas_ta as ta\n",
    "import getData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting stock price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_param = {\n",
    "    'win_size':22,\n",
    "    'stride':1,\n",
    "    'split':True,\n",
    "    'number_y':1,\n",
    "    'random_state':420,\n",
    "    'test_size':0.2,\n",
    "}\n",
    "\n",
    "v_preprocess_param = {\n",
    "    'win_size':22,\n",
    "    'stride':1,\n",
    "    'split':False,\n",
    "    'number_y':1,\n",
    "    'random_state':420,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = 'BTC-USD'\n",
    "\n",
    "prices_df = getData.loader(tickers=tickers, interval=\"1d\", period='max', end=\"2023-01-01\").dataframe\n",
    "prices_df_val = getData.loader(tickers=tickers, interval=\"1d\", start='2023-01-01').dataframe\n",
    "\n",
    "datasets = getData.preprocessor(prices_df, preprocess_param=preprocess_param).dataset\n",
    "val_sets = getData.preprocessor(prices_df_val, preprocess_param=v_preprocess_param).dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class PriceHistoryDataset(Dataset):\n",
    "    def __init__(self, dataset, to_predict=['Open', 'High', 'Low', 'Close']):\n",
    "        y = dataset['y'][:,:,self.__map_to_indices(to_predict)]\n",
    "        x = dataset['x']\n",
    "        self.columns = dataset['columns']\n",
    "        self.initial_price = dataset['initial price']\n",
    "        self.current_date = dataset['current date']\n",
    "        \n",
    "        self.X = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y).float()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    def __map_to_indices(self, args):\n",
    "        mapping = {'Open': 0, 'High': 1, 'Low': 2, 'Close': 3}\n",
    "        return [mapping[arg] for arg in args]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = datasets['columns']\n",
    "\n",
    "to_predict = ['Close']\n",
    "\n",
    "train_set = PriceHistoryDataset(datasets['train'], to_predict)\n",
    "test_set = PriceHistoryDataset(datasets['test'], to_predict)\n",
    "val_set = PriceHistoryDataset(val_sets, to_predict)\n",
    "\n",
    "train_loader= DataLoader(train_set, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=256, shuffle=False)\n",
    "val_loader = DataLoader(val_set, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class LSTMModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, hidden_size, lstm_layers, head_layers, input_size=8, output_size=3, dropout=0.05):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.gru = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=lstm_layers)\n",
    "        \n",
    "        self.linears = nn.ModuleList([\n",
    "            nn.Linear(hidden_size, hidden_size) for _ in range(head_layers-1)\n",
    "        ])\n",
    "        \n",
    "        self.out_linear = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # keep track of losses function.\n",
    "        self.train_losses = []\n",
    "        self.test_losses = []\n",
    "        self.loss_func = nn.L1Loss()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.gru(x)\n",
    "        o = lstm_out[:,-1:,:]\n",
    "        \n",
    "        for linear in self.linears:\n",
    "            o = linear(o)\n",
    "        \n",
    "        output = self.out_linear(o)\n",
    "        return output\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_func(y, y_hat)#.mean()\n",
    "        self.train_losses.append(loss)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_func(y, y_hat)#.mean()\n",
    "        self.test_losses.append(loss)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def on_test_epoch_end(self):\n",
    "        avg_loss = torch.stack(self.test_losses).mean()\n",
    "        print(f'Test Loss: {avg_loss}')\n",
    "        return {'L1_loss': avg_loss}\n",
    "    \n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        avg_loss = torch.stack(self.train_losses).mean()\n",
    "        print(f'Train Loss: {avg_loss}')\n",
    "        return {'L1_loss': avg_loss}\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "# Initialize the model and trainer\n",
    "model = LSTMModel(output_size=len(to_predict), hidden_size=128, lstm_layers=5, head_layers=1, dropout=0.0)\n",
    "# model = LSTMModel.load_from_checkpoint(\"/model/lightning_logs/vsrsion_.../checkpoints/....ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 2178305\n",
      "Number of layers: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of parameters:\", sum(p.numel() for p in model.parameters()))\n",
    "print(\"Number of layers:\", len(list(model.children())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | gru        | GRU        | 2.2 M \n",
      "1 | linears    | ModuleList | 0     \n",
      "2 | out_linear | Linear     | 257   \n",
      "3 | loss_func  | L1Loss     | 0     \n",
      "------------------------------------------\n",
      "2.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 M     Total params\n",
      "8.713     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930e99743e6f43c1aac2d2e2fa28ea4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.317134141921997\n",
      "Train Loss: 0.8205096125602722\n",
      "Train Loss: 0.627629816532135\n",
      "Train Loss: 0.5258581042289734\n",
      "Train Loss: 0.460901141166687\n",
      "Train Loss: 0.41622135043144226\n",
      "Train Loss: 0.3842693269252777\n",
      "Train Loss: 0.36048194766044617\n",
      "Train Loss: 0.34196341037750244\n",
      "Train Loss: 0.3271113932132721\n",
      "Train Loss: 0.31503671407699585\n",
      "Train Loss: 0.305474191904068\n",
      "Train Loss: 0.2974328398704529\n",
      "Train Loss: 0.2905840277671814\n",
      "Train Loss: 0.28457939624786377\n",
      "Train Loss: 0.2796282172203064\n",
      "Train Loss: 0.27535876631736755\n",
      "Train Loss: 0.2716987431049347\n",
      "Train Loss: 0.2679847478866577\n",
      "Train Loss: 0.2647670805454254\n",
      "Train Loss: 0.2617131173610687\n",
      "Train Loss: 0.25931400060653687\n",
      "Train Loss: 0.25694510340690613\n",
      "Train Loss: 0.2548977732658386\n",
      "Train Loss: 0.2529011368751526\n",
      "Train Loss: 0.251144140958786\n",
      "Train Loss: 0.24951927363872528\n",
      "Train Loss: 0.24806205928325653\n",
      "Train Loss: 0.24649740755558014\n",
      "Train Loss: 0.24514292180538177\n",
      "Train Loss: 0.24391278624534607\n",
      "Train Loss: 0.24285782873630524\n",
      "Train Loss: 0.24166838824748993\n",
      "Train Loss: 0.24049681425094604\n",
      "Train Loss: 0.2393033504486084\n",
      "Train Loss: 0.23825332522392273\n",
      "Train Loss: 0.23711568117141724\n",
      "Train Loss: 0.23597945272922516\n",
      "Train Loss: 0.23494991660118103\n",
      "Train Loss: 0.23392686247825623\n",
      "Train Loss: 0.23291654884815216\n",
      "Train Loss: 0.23198668658733368\n",
      "Train Loss: 0.23126818239688873\n",
      "Train Loss: 0.2308289259672165\n",
      "Train Loss: 0.23060891032218933\n",
      "Train Loss: 0.23024670779705048\n",
      "Train Loss: 0.22974292933940887\n",
      "Train Loss: 0.22928905487060547\n",
      "Train Loss: 0.22899822890758514\n",
      "Train Loss: 0.2285446971654892\n",
      "Train Loss: 0.2281191349029541\n",
      "Train Loss: 0.22779473662376404\n",
      "Train Loss: 0.22743284702301025\n",
      "Train Loss: 0.227015420794487\n",
      "Train Loss: 0.22659975290298462\n",
      "Train Loss: 0.22609056532382965\n",
      "Train Loss: 0.22564804553985596\n",
      "Train Loss: 0.2252020239830017\n",
      "Train Loss: 0.22478578984737396\n",
      "Train Loss: 0.22439147531986237\n",
      "Train Loss: 0.22419244050979614\n",
      "Train Loss: 0.2239576131105423\n",
      "Train Loss: 0.2236746996641159\n",
      "Train Loss: 0.2234126776456833\n",
      "Train Loss: 0.2232239842414856\n",
      "Train Loss: 0.2228952795267105\n",
      "Train Loss: 0.2225879728794098\n",
      "Train Loss: 0.22229911386966705\n",
      "Train Loss: 0.22199277579784393\n",
      "Train Loss: 0.22167550027370453\n",
      "Train Loss: 0.22148841619491577\n",
      "Train Loss: 0.2212800681591034\n",
      "Train Loss: 0.22104501724243164\n",
      "Train Loss: 0.220823734998703\n",
      "Train Loss: 0.2206263393163681\n",
      "Train Loss: 0.22045741975307465\n",
      "Train Loss: 0.22023430466651917\n",
      "Train Loss: 0.21992331743240356\n",
      "Train Loss: 0.21971939504146576\n",
      "Train Loss: 0.21952687203884125\n",
      "Train Loss: 0.21933186054229736\n",
      "Train Loss: 0.2191449999809265\n",
      "Train Loss: 0.21896810829639435\n",
      "Train Loss: 0.21874980628490448\n",
      "Train Loss: 0.21857064962387085\n",
      "Train Loss: 0.21830900013446808\n",
      "Train Loss: 0.21814049780368805\n",
      "Train Loss: 0.2180611938238144\n",
      "Train Loss: 0.2179018259048462\n",
      "Train Loss: 0.21767835319042206\n",
      "Train Loss: 0.21755489706993103\n",
      "Train Loss: 0.2174820750951767\n",
      "Train Loss: 0.21731998026371002\n",
      "Train Loss: 0.21709761023521423\n",
      "Train Loss: 0.21692825853824615\n",
      "Train Loss: 0.21682074666023254\n",
      "Train Loss: 0.21676205098628998\n",
      "Train Loss: 0.2166413515806198\n",
      "Train Loss: 0.21647652983665466\n",
      "Train Loss: 0.216258242726326\n",
      "Train Loss: 0.21607688069343567\n",
      "Train Loss: 0.215917706489563\n",
      "Train Loss: 0.21579551696777344\n",
      "Train Loss: 0.21574817597866058\n",
      "Train Loss: 0.2156202495098114\n",
      "Train Loss: 0.21542079746723175\n",
      "Train Loss: 0.2152697890996933\n",
      "Train Loss: 0.21510477364063263\n",
      "Train Loss: 0.21501818299293518\n",
      "Train Loss: 0.21501263976097107\n",
      "Train Loss: 0.21493041515350342\n",
      "Train Loss: 0.2147708535194397\n",
      "Train Loss: 0.21466064453125\n",
      "Train Loss: 0.21458646655082703\n",
      "Train Loss: 0.2145528942346573\n",
      "Train Loss: 0.21446119248867035\n",
      "Train Loss: 0.2143879234790802\n",
      "Train Loss: 0.21431078016757965\n",
      "Train Loss: 0.21425513923168182\n",
      "Train Loss: 0.21413938701152802\n",
      "Train Loss: 0.2140435129404068\n",
      "Train Loss: 0.21394746005535126\n",
      "Train Loss: 0.2138693630695343\n",
      "Train Loss: 0.21378178894519806\n",
      "Train Loss: 0.21373899281024933\n",
      "Train Loss: 0.2136489897966385\n",
      "Train Loss: 0.2135908454656601\n",
      "Train Loss: 0.2134670615196228\n",
      "Train Loss: 0.21352030336856842\n",
      "Train Loss: 0.21346937119960785\n",
      "Train Loss: 0.2133365124464035\n",
      "Train Loss: 0.21317900717258453\n",
      "Train Loss: 0.21304576098918915\n",
      "Train Loss: 0.2128986269235611\n",
      "Train Loss: 0.21274085342884064\n",
      "Train Loss: 0.21264418959617615\n",
      "Train Loss: 0.21252775192260742\n",
      "Train Loss: 0.212394580245018\n",
      "Train Loss: 0.21234026551246643\n",
      "Train Loss: 0.21235521137714386\n",
      "Train Loss: 0.21234819293022156\n",
      "Train Loss: 0.21228308975696564\n",
      "Train Loss: 0.21222810447216034\n",
      "Train Loss: 0.21216411888599396\n",
      "Train Loss: 0.21212492883205414\n",
      "Train Loss: 0.2121000438928604\n",
      "Train Loss: 0.21203432977199554\n",
      "Train Loss: 0.21191392838954926\n",
      "Train Loss: 0.21183425188064575\n",
      "Train Loss: 0.2117300033569336\n",
      "Train Loss: 0.21160446107387543\n",
      "Train Loss: 0.21153362095355988\n",
      "Train Loss: 0.21145711839199066\n",
      "Train Loss: 0.21148373186588287\n",
      "Train Loss: 0.21158722043037415\n",
      "Train Loss: 0.21160314977169037\n",
      "Train Loss: 0.21163173019886017\n",
      "Train Loss: 0.21157345175743103\n",
      "Train Loss: 0.21149952709674835\n",
      "Train Loss: 0.21141797304153442\n",
      "Train Loss: 0.21138077974319458\n",
      "Train Loss: 0.21134409308433533\n",
      "Train Loss: 0.21126239001750946\n",
      "Train Loss: 0.21116505563259125\n",
      "Train Loss: 0.21113064885139465\n",
      "Train Loss: 0.21112632751464844\n",
      "Train Loss: 0.21106277406215668\n",
      "Train Loss: 0.2109595537185669\n",
      "Train Loss: 0.210902601480484\n",
      "Train Loss: 0.21086497604846954\n",
      "Train Loss: 0.2108057141304016\n",
      "Train Loss: 0.21071934700012207\n",
      "Train Loss: 0.21066750586032867\n",
      "Train Loss: 0.21059885621070862\n",
      "Train Loss: 0.21053917706012726\n",
      "Train Loss: 0.21047359704971313\n",
      "Train Loss: 0.2104426622390747\n",
      "Train Loss: 0.21036067605018616\n",
      "Train Loss: 0.21034708619117737\n",
      "Train Loss: 0.21031954884529114\n",
      "Train Loss: 0.21026228368282318\n",
      "Train Loss: 0.2101806104183197\n",
      "Train Loss: 0.21015092730522156\n",
      "Train Loss: 0.21013566851615906\n",
      "Train Loss: 0.2100825309753418\n",
      "Train Loss: 0.20999914407730103\n",
      "Train Loss: 0.2099473625421524\n",
      "Train Loss: 0.20988591015338898\n",
      "Train Loss: 0.2098570466041565\n",
      "Train Loss: 0.20984911918640137\n",
      "Train Loss: 0.20981071889400482\n",
      "Train Loss: 0.20974215865135193\n",
      "Train Loss: 0.2097228616476059\n",
      "Train Loss: 0.2097102403640747\n",
      "Train Loss: 0.20964482426643372\n",
      "Train Loss: 0.20955756306648254\n",
      "Train Loss: 0.2095024287700653\n",
      "Train Loss: 0.20942886173725128\n",
      "Train Loss: 0.20938117802143097\n",
      "Train Loss: 0.2093524932861328\n",
      "Train Loss: 0.20932817459106445\n",
      "Train Loss: 0.20927837491035461\n",
      "Train Loss: 0.2093743085861206\n",
      "Train Loss: 0.20956966280937195\n",
      "Train Loss: 0.2096787542104721\n",
      "Train Loss: 0.20990775525569916\n",
      "Train Loss: 0.21018941700458527\n",
      "Train Loss: 0.21028806269168854\n",
      "Train Loss: 0.21023434400558472\n",
      "Train Loss: 0.21023808419704437\n",
      "Train Loss: 0.21023860573768616\n",
      "Train Loss: 0.21018853783607483\n",
      "Train Loss: 0.21011537313461304\n",
      "Train Loss: 0.21008417010307312\n",
      "Train Loss: 0.21008294820785522\n",
      "Train Loss: 0.21004518866539001\n",
      "Train Loss: 0.21000432968139648\n",
      "Train Loss: 0.20998279750347137\n",
      "Train Loss: 0.20994944870471954\n",
      "Train Loss: 0.20991671085357666\n",
      "Train Loss: 0.20987871289253235\n",
      "Train Loss: 0.20986385643482208\n",
      "Train Loss: 0.20983903110027313\n",
      "Train Loss: 0.20981010794639587\n",
      "Train Loss: 0.2097611129283905\n",
      "Train Loss: 0.20974645018577576\n",
      "Train Loss: 0.20975887775421143\n",
      "Train Loss: 0.20970147848129272\n",
      "Train Loss: 0.2096274197101593\n",
      "Train Loss: 0.20955339074134827\n",
      "Train Loss: 0.20951181650161743\n",
      "Train Loss: 0.2094964236021042\n",
      "Train Loss: 0.2094896286725998\n",
      "Train Loss: 0.2094532549381256\n",
      "Train Loss: 0.20943136513233185\n",
      "Train Loss: 0.20940595865249634\n",
      "Train Loss: 0.20939095318317413\n",
      "Train Loss: 0.20936806499958038\n",
      "Train Loss: 0.20933115482330322\n",
      "Train Loss: 0.20928509533405304\n",
      "Train Loss: 0.20927037298679352\n",
      "Train Loss: 0.20925474166870117\n",
      "Train Loss: 0.2092200517654419\n",
      "Train Loss: 0.20915643870830536\n",
      "Train Loss: 0.2091057300567627\n",
      "Train Loss: 0.2090565264225006\n",
      "Train Loss: 0.20903410017490387\n",
      "Train Loss: 0.20901364088058472\n",
      "Train Loss: 0.20901697874069214\n",
      "Train Loss: 0.20901651680469513\n",
      "Train Loss: 0.20898213982582092\n",
      "Train Loss: 0.2089444100856781\n",
      "Train Loss: 0.2089451253414154\n",
      "Train Loss: 0.20892678201198578\n",
      "Train Loss: 0.20889678597450256\n",
      "Train Loss: 0.20885923504829407\n",
      "Train Loss: 0.20884549617767334\n",
      "Train Loss: 0.20884324610233307\n",
      "Train Loss: 0.20880848169326782\n",
      "Train Loss: 0.2087552547454834\n",
      "Train Loss: 0.20873717963695526\n",
      "Train Loss: 0.20874589681625366\n",
      "Train Loss: 0.2087152898311615\n",
      "Train Loss: 0.20866480469703674\n",
      "Train Loss: 0.20864130556583405\n",
      "Train Loss: 0.2086181491613388\n",
      "Train Loss: 0.2086154669523239\n",
      "Train Loss: 0.20860593020915985\n",
      "Train Loss: 0.2085830420255661\n",
      "Train Loss: 0.20855873823165894\n",
      "Train Loss: 0.20855827629566193\n",
      "Train Loss: 0.20854566991329193\n",
      "Train Loss: 0.2085285484790802\n",
      "Train Loss: 0.2085074484348297\n",
      "Train Loss: 0.20849193632602692\n",
      "Train Loss: 0.20846135914325714\n",
      "Train Loss: 0.20844119787216187\n",
      "Train Loss: 0.20841749012470245\n",
      "Train Loss: 0.20839694142341614\n",
      "Train Loss: 0.2083602398633957\n",
      "Train Loss: 0.20834757387638092\n",
      "Train Loss: 0.20832227170467377\n",
      "Train Loss: 0.2083156704902649\n",
      "Train Loss: 0.20829574763774872\n",
      "Train Loss: 0.20832867920398712\n",
      "Train Loss: 0.20984432101249695\n",
      "Train Loss: 0.21346649527549744\n",
      "Train Loss: 0.21713820099830627\n",
      "Train Loss: 0.2211359590291977\n",
      "Train Loss: 0.2222772091627121\n",
      "Train Loss: 0.22250902652740479\n",
      "Train Loss: 0.22255171835422516\n",
      "Train Loss: 0.22251121699810028\n",
      "Train Loss: 0.22241567075252533\n",
      "Train Loss: 0.22232557833194733\n",
      "Train Loss: 0.22223757207393646\n",
      "Train Loss: 0.2221427708864212\n",
      "Train Loss: 0.2220620959997177\n",
      "Train Loss: 0.22196805477142334\n",
      "Train Loss: 0.22188571095466614\n",
      "Train Loss: 0.22179460525512695\n",
      "Train Loss: 0.2217160165309906\n",
      "Train Loss: 0.22162239253520966\n",
      "Train Loss: 0.22154958546161652\n",
      "Train Loss: 0.22147899866104126\n",
      "Train Loss: 0.22142890095710754\n",
      "Train Loss: 0.2213417887687683\n",
      "Train Loss: 0.22125326097011566\n",
      "Train Loss: 0.22118429839611053\n",
      "Train Loss: 0.22110968828201294\n",
      "Train Loss: 0.22107942402362823\n",
      "Train Loss: 0.22107340395450592\n",
      "Train Loss: 0.2210233509540558\n",
      "Train Loss: 0.220943883061409\n",
      "Train Loss: 0.22087673842906952\n",
      "Train Loss: 0.2207900732755661\n",
      "Train Loss: 0.22070376574993134\n",
      "Train Loss: 0.22061854600906372\n",
      "Train Loss: 0.22053642570972443\n",
      "Train Loss: 0.22046343982219696\n",
      "Train Loss: 0.22038060426712036\n",
      "Train Loss: 0.2203081101179123\n",
      "Train Loss: 0.2202252894639969\n",
      "Train Loss: 0.22014549374580383\n",
      "Train Loss: 0.2200656682252884\n",
      "Train Loss: 0.22000129520893097\n",
      "Train Loss: 0.21994686126708984\n",
      "Train Loss: 0.21994677186012268\n",
      "Train Loss: 0.21997664868831635\n",
      "Train Loss: 0.21991446614265442\n",
      "Train Loss: 0.21983173489570618\n",
      "Train Loss: 0.21975260972976685\n",
      "Train Loss: 0.21967625617980957\n",
      "Train Loss: 0.21959912776947021\n",
      "Train Loss: 0.2195233255624771\n",
      "Train Loss: 0.21945956349372864\n",
      "Train Loss: 0.21939672529697418\n",
      "Train Loss: 0.21934214234352112\n",
      "Train Loss: 0.21926546096801758\n",
      "Train Loss: 0.21919748187065125\n",
      "Train Loss: 0.21913005411624908\n",
      "Train Loss: 0.21905677020549774\n",
      "Train Loss: 0.21898110210895538\n",
      "Train Loss: 0.21892796456813812\n",
      "Train Loss: 0.21885818243026733\n",
      "Train Loss: 0.21878014504909515\n",
      "Train Loss: 0.21870830655097961\n",
      "Train Loss: 0.2186507284641266\n",
      "Train Loss: 0.21859337389469147\n",
      "Train Loss: 0.21852515637874603\n",
      "Train Loss: 0.21848136186599731\n",
      "Train Loss: 0.21843241155147552\n",
      "Train Loss: 0.21837352216243744\n",
      "Train Loss: 0.21831287443637848\n",
      "Train Loss: 0.21824361383914948\n",
      "Train Loss: 0.2181912362575531\n",
      "Train Loss: 0.21813175082206726\n",
      "Train Loss: 0.21806424856185913\n",
      "Train Loss: 0.2179972231388092\n",
      "Train Loss: 0.2179683893918991\n",
      "Train Loss: 0.21791867911815643\n",
      "Train Loss: 0.21790552139282227\n",
      "Train Loss: 0.21786361932754517\n",
      "Train Loss: 0.21787339448928833\n",
      "Train Loss: 0.2179017812013626\n",
      "Train Loss: 0.21787501871585846\n",
      "Train Loss: 0.2178279459476471\n",
      "Train Loss: 0.21778394281864166\n",
      "Train Loss: 0.2177184373140335\n",
      "Train Loss: 0.2176632285118103\n",
      "Train Loss: 0.21759763360023499\n",
      "Train Loss: 0.21752910315990448\n",
      "Train Loss: 0.21749548614025116\n",
      "Train Loss: 0.21745073795318604\n",
      "Train Loss: 0.21738995611667633\n",
      "Train Loss: 0.21732836961746216\n",
      "Train Loss: 0.217279314994812\n",
      "Train Loss: 0.21723364293575287\n",
      "Train Loss: 0.2171870321035385\n",
      "Train Loss: 0.2171439528465271\n",
      "Train Loss: 0.21712297201156616\n",
      "Train Loss: 0.21712258458137512\n",
      "Train Loss: 0.21712876856327057\n",
      "Train Loss: 0.2170991152524948\n",
      "Train Loss: 0.21705374121665955\n",
      "Train Loss: 0.21704834699630737\n",
      "Train Loss: 0.2170688658952713\n",
      "Train Loss: 0.2170240432024002\n",
      "Train Loss: 0.21696245670318604\n",
      "Train Loss: 0.21690703928470612\n",
      "Train Loss: 0.21684689819812775\n",
      "Train Loss: 0.21678566932678223\n",
      "Train Loss: 0.21672697365283966\n",
      "Train Loss: 0.21667642891407013\n",
      "Train Loss: 0.216631218791008\n",
      "Train Loss: 0.21661269664764404\n",
      "Train Loss: 0.21657007932662964\n",
      "Train Loss: 0.21651482582092285\n",
      "Train Loss: 0.21647541224956512\n",
      "Train Loss: 0.21643075346946716\n",
      "Train Loss: 0.21638886630535126\n",
      "Train Loss: 0.21634460985660553\n",
      "Train Loss: 0.21630536019802094\n",
      "Train Loss: 0.21628427505493164\n",
      "Train Loss: 0.21622996032238007\n",
      "Train Loss: 0.21617315709590912\n",
      "Train Loss: 0.2161329686641693\n",
      "Train Loss: 0.216090127825737\n",
      "Train Loss: 0.21605411171913147\n",
      "Train Loss: 0.21600636839866638\n",
      "Train Loss: 0.21595214307308197\n",
      "Train Loss: 0.21589842438697815\n",
      "Train Loss: 0.21585004031658173\n",
      "Train Loss: 0.2158050686120987\n",
      "Train Loss: 0.21575197577476501\n",
      "Train Loss: 0.21569567918777466\n",
      "Train Loss: 0.215657040476799\n",
      "Train Loss: 0.21560953557491302\n",
      "Train Loss: 0.21556377410888672\n",
      "Train Loss: 0.2155115008354187\n",
      "Train Loss: 0.21545806527137756\n",
      "Train Loss: 0.2154066115617752\n",
      "Train Loss: 0.21535471081733704\n",
      "Train Loss: 0.2153133749961853\n",
      "Train Loss: 0.21526604890823364\n",
      "Train Loss: 0.21521613001823425\n",
      "Train Loss: 0.21517303586006165\n",
      "Train Loss: 0.21513378620147705\n",
      "Train Loss: 0.21508559584617615\n",
      "Train Loss: 0.2150340974330902\n",
      "Train Loss: 0.21500881016254425\n",
      "Train Loss: 0.2149660587310791\n",
      "Train Loss: 0.21491535007953644\n",
      "Train Loss: 0.21487127244472504\n",
      "Train Loss: 0.2148350179195404\n",
      "Train Loss: 0.21479035913944244\n",
      "Train Loss: 0.21474477648735046\n",
      "Train Loss: 0.2147025614976883\n",
      "Train Loss: 0.21465109288692474\n",
      "Train Loss: 0.214600071310997\n",
      "Train Loss: 0.21454846858978271\n",
      "Train Loss: 0.21450366079807281\n",
      "Train Loss: 0.2144559919834137\n",
      "Train Loss: 0.21441532671451569\n",
      "Train Loss: 0.21438276767730713\n",
      "Train Loss: 0.21435102820396423\n",
      "Train Loss: 0.2143138349056244\n",
      "Train Loss: 0.21428586542606354\n",
      "Train Loss: 0.21425019204616547\n",
      "Train Loss: 0.21422645449638367\n",
      "Train Loss: 0.2141900360584259\n",
      "Train Loss: 0.21416103839874268\n",
      "Train Loss: 0.21412068605422974\n",
      "Train Loss: 0.2140873670578003\n",
      "Train Loss: 0.2140587419271469\n",
      "Train Loss: 0.2140277475118637\n",
      "Train Loss: 0.21399427950382233\n",
      "Train Loss: 0.2139621078968048\n",
      "Train Loss: 0.2139306366443634\n",
      "Train Loss: 0.21390093863010406\n",
      "Train Loss: 0.21386736631393433\n",
      "Train Loss: 0.21384672820568085\n",
      "Train Loss: 0.21381357312202454\n",
      "Train Loss: 0.21378564834594727\n",
      "Train Loss: 0.21378666162490845\n",
      "Train Loss: 0.21378067135810852\n",
      "Train Loss: 0.21376372873783112\n",
      "Train Loss: 0.21374085545539856\n",
      "Train Loss: 0.21370233595371246\n",
      "Train Loss: 0.21366822719573975\n",
      "Train Loss: 0.21363654732704163\n",
      "Train Loss: 0.21360814571380615\n",
      "Train Loss: 0.21357791125774384\n",
      "Train Loss: 0.21354758739471436\n",
      "Train Loss: 0.2135077714920044\n",
      "Train Loss: 0.21347257494926453\n",
      "Train Loss: 0.21344299614429474\n",
      "Train Loss: 0.21341034770011902\n",
      "Train Loss: 0.21338631212711334\n",
      "Train Loss: 0.2133619785308838\n",
      "Train Loss: 0.21333047747612\n",
      "Train Loss: 0.21330411732196808\n",
      "Train Loss: 0.2132745236158371\n",
      "Train Loss: 0.2132381647825241\n",
      "Train Loss: 0.21320731937885284\n",
      "Train Loss: 0.21317146718502045\n",
      "Train Loss: 0.21313150227069855\n",
      "Train Loss: 0.21309207379817963\n",
      "Train Loss: 0.2130516618490219\n",
      "Train Loss: 0.21301023662090302\n",
      "Train Loss: 0.21297144889831543\n",
      "Train Loss: 0.21295204758644104\n",
      "Train Loss: 0.21291661262512207\n",
      "Train Loss: 0.2128787636756897\n",
      "Train Loss: 0.21284520626068115\n",
      "Train Loss: 0.21281197667121887\n",
      "Train Loss: 0.21278779208660126\n",
      "Train Loss: 0.2127677947282791\n",
      "Train Loss: 0.21273939311504364\n",
      "Train Loss: 0.2127171754837036\n",
      "Train Loss: 0.21268311142921448\n",
      "Train Loss: 0.21264879405498505\n",
      "Train Loss: 0.21261721849441528\n",
      "Train Loss: 0.21259085834026337\n",
      "Train Loss: 0.21257072687149048\n",
      "Train Loss: 0.21256445348262787\n",
      "Train Loss: 0.21253235638141632\n",
      "Train Loss: 0.212497740983963\n",
      "Train Loss: 0.2125052660703659\n",
      "Train Loss: 0.2124752700328827\n",
      "Train Loss: 0.21243546903133392\n",
      "Train Loss: 0.2123992145061493\n",
      "Train Loss: 0.21236711740493774\n",
      "Train Loss: 0.21235491335391998\n",
      "Train Loss: 0.21232648193836212\n",
      "Train Loss: 0.21228843927383423\n",
      "Train Loss: 0.21226172149181366\n",
      "Train Loss: 0.21224242448806763\n",
      "Train Loss: 0.21222704648971558\n",
      "Train Loss: 0.2121957391500473\n",
      "Train Loss: 0.21215689182281494\n",
      "Train Loss: 0.21212787926197052\n",
      "Train Loss: 0.2120969593524933\n",
      "Train Loss: 0.2120865285396576\n",
      "Train Loss: 0.21205973625183105\n",
      "Train Loss: 0.21203744411468506\n",
      "Train Loss: 0.21201153099536896\n",
      "Train Loss: 0.21197868883609772\n",
      "Train Loss: 0.21194490790367126\n",
      "Train Loss: 0.21192412078380585\n",
      "Train Loss: 0.21191570162773132\n",
      "Train Loss: 0.2118927538394928\n",
      "Train Loss: 0.2118648737668991\n",
      "Train Loss: 0.21186837553977966\n",
      "Train Loss: 0.21184788644313812\n",
      "Train Loss: 0.21182523667812347\n",
      "Train Loss: 0.21179881691932678\n",
      "Train Loss: 0.2117665708065033\n",
      "Train Loss: 0.21175119280815125\n",
      "Train Loss: 0.21172568202018738\n",
      "Train Loss: 0.2116902619600296\n",
      "Train Loss: 0.21165673434734344\n",
      "Train Loss: 0.2116367071866989\n",
      "Train Loss: 0.2116546630859375\n",
      "Train Loss: 0.2116471230983734\n",
      "Train Loss: 0.21162723004817963\n",
      "Train Loss: 0.2116096019744873\n",
      "Train Loss: 0.2115880846977234\n",
      "Train Loss: 0.2115660160779953\n",
      "Train Loss: 0.21154356002807617\n",
      "Train Loss: 0.21152028441429138\n",
      "Train Loss: 0.21149861812591553\n",
      "Train Loss: 0.21147669851779938\n",
      "Train Loss: 0.21144670248031616\n",
      "Train Loss: 0.21141497790813446\n",
      "Train Loss: 0.21138806641101837\n",
      "Train Loss: 0.21137191355228424\n",
      "Train Loss: 0.21135561168193817\n",
      "Train Loss: 0.2113342136144638\n",
      "Train Loss: 0.2113303393125534\n",
      "Train Loss: 0.21131639182567596\n",
      "Train Loss: 0.21129274368286133\n",
      "Train Loss: 0.21126875281333923\n",
      "Train Loss: 0.2112521082162857\n",
      "Train Loss: 0.21122317016124725\n",
      "Train Loss: 0.21119000017642975\n",
      "Train Loss: 0.21116629242897034\n",
      "Train Loss: 0.21114003658294678\n",
      "Train Loss: 0.21111981570720673\n",
      "Train Loss: 0.21109738945960999\n",
      "Train Loss: 0.21107763051986694\n",
      "Train Loss: 0.21105556190013885\n",
      "Train Loss: 0.21103724837303162\n",
      "Train Loss: 0.2110135555267334\n",
      "Train Loss: 0.21099843084812164\n",
      "Train Loss: 0.21097058057785034\n",
      "Train Loss: 0.2109391689300537\n",
      "Train Loss: 0.21091504395008087\n",
      "Train Loss: 0.21088998019695282\n",
      "Train Loss: 0.21087825298309326\n",
      "Train Loss: 0.21086125075817108\n",
      "Train Loss: 0.21083900332450867\n",
      "Train Loss: 0.2108527421951294\n",
      "Train Loss: 0.21084614098072052\n",
      "Train Loss: 0.21082815527915955\n",
      "Train Loss: 0.21080677211284637\n",
      "Train Loss: 0.21078792214393616\n",
      "Train Loss: 0.21075977385044098\n",
      "Train Loss: 0.21072933077812195\n",
      "Train Loss: 0.2107074111700058\n",
      "Train Loss: 0.2106892615556717\n",
      "Train Loss: 0.21067050099372864\n",
      "Train Loss: 0.21064883470535278\n",
      "Train Loss: 0.21063369512557983\n",
      "Train Loss: 0.2106148600578308\n",
      "Train Loss: 0.21059367060661316\n",
      "Train Loss: 0.21057504415512085\n",
      "Train Loss: 0.2105502337217331\n",
      "Train Loss: 0.21053312718868256\n",
      "Train Loss: 0.2105090618133545\n",
      "Train Loss: 0.2104833871126175\n",
      "Train Loss: 0.21046790480613708\n",
      "Train Loss: 0.21044385433197021\n",
      "Train Loss: 0.2104136198759079\n",
      "Train Loss: 0.21038487553596497\n",
      "Train Loss: 0.2103564441204071\n",
      "Train Loss: 0.2103298008441925\n",
      "Train Loss: 0.21030060946941376\n",
      "Train Loss: 0.21027036011219025\n",
      "Train Loss: 0.2102489471435547\n",
      "Train Loss: 0.21022626757621765\n",
      "Train Loss: 0.2102099359035492\n",
      "Train Loss: 0.210195392370224\n",
      "Train Loss: 0.2101820409297943\n",
      "Train Loss: 0.21016378700733185\n",
      "Train Loss: 0.21014800667762756\n",
      "Train Loss: 0.2101329267024994\n",
      "Train Loss: 0.21011759340763092\n",
      "Train Loss: 0.21010898053646088\n",
      "Train Loss: 0.2100864201784134\n",
      "Train Loss: 0.2100595086812973\n",
      "Train Loss: 0.2100355327129364\n",
      "Train Loss: 0.2100197970867157\n",
      "Train Loss: 0.2100059986114502\n",
      "Train Loss: 0.20999635756015778\n",
      "Train Loss: 0.20997431874275208\n",
      "Train Loss: 0.20994910597801208\n",
      "Train Loss: 0.20992453396320343\n",
      "Train Loss: 0.20990797877311707\n",
      "Train Loss: 0.2098991721868515\n",
      "Train Loss: 0.2098764181137085\n",
      "Train Loss: 0.20984844863414764\n",
      "Train Loss: 0.20982244610786438\n",
      "Train Loss: 0.20980027318000793\n",
      "Train Loss: 0.20977911353111267\n",
      "Train Loss: 0.20975834131240845\n",
      "Train Loss: 0.20973753929138184\n",
      "Train Loss: 0.20972265303134918\n",
      "Train Loss: 0.2097235471010208\n",
      "Train Loss: 0.20970699191093445\n",
      "Train Loss: 0.2096848338842392\n",
      "Train Loss: 0.20970401167869568\n",
      "Train Loss: 0.20969702303409576\n",
      "Train Loss: 0.20967994630336761\n",
      "Train Loss: 0.20966516435146332\n",
      "Train Loss: 0.20964819192886353\n",
      "Train Loss: 0.20963764190673828\n",
      "Train Loss: 0.2096150666475296\n",
      "Train Loss: 0.20958910882472992\n",
      "Train Loss: 0.20956450700759888\n",
      "Train Loss: 0.2095431685447693\n",
      "Train Loss: 0.20952625572681427\n",
      "Train Loss: 0.20951682329177856\n",
      "Train Loss: 0.20950128138065338\n",
      "Train Loss: 0.20948927104473114\n",
      "Train Loss: 0.20947258174419403\n",
      "Train Loss: 0.2094559669494629\n",
      "Train Loss: 0.20944267511367798\n",
      "Train Loss: 0.20942795276641846\n",
      "Train Loss: 0.20941634476184845\n",
      "Train Loss: 0.20939838886260986\n",
      "Train Loss: 0.20937463641166687\n",
      "Train Loss: 0.20935048162937164\n",
      "Train Loss: 0.20933252573013306\n",
      "Train Loss: 0.20931679010391235\n",
      "Train Loss: 0.20930276811122894\n",
      "Train Loss: 0.20929890871047974\n",
      "Train Loss: 0.2092801183462143\n",
      "Train Loss: 0.20925508439540863\n",
      "Train Loss: 0.2092379480600357\n",
      "Train Loss: 0.20921902358531952\n",
      "Train Loss: 0.20920534431934357\n",
      "Train Loss: 0.20920327305793762\n",
      "Train Loss: 0.20919297635555267\n",
      "Train Loss: 0.20917712152004242\n",
      "Train Loss: 0.20919665694236755\n",
      "Train Loss: 0.20918993651866913\n",
      "Train Loss: 0.20917071402072906\n",
      "Train Loss: 0.20915058255195618\n",
      "Train Loss: 0.2091328203678131\n",
      "Train Loss: 0.20912683010101318\n",
      "Train Loss: 0.20910866558551788\n",
      "Train Loss: 0.20908556878566742\n",
      "Train Loss: 0.20906610786914825\n",
      "Train Loss: 0.20904600620269775\n",
      "Train Loss: 0.20902633666992188\n",
      "Train Loss: 0.20900499820709229\n",
      "Train Loss: 0.20898514986038208\n",
      "Train Loss: 0.2089703232049942\n",
      "Train Loss: 0.2089591920375824\n",
      "Train Loss: 0.2089504599571228\n",
      "Train Loss: 0.20893681049346924\n",
      "Train Loss: 0.20892411470413208\n",
      "Train Loss: 0.20890918374061584\n",
      "Train Loss: 0.20889829099178314\n",
      "Train Loss: 0.20887917280197144\n",
      "Train Loss: 0.20885615050792694\n",
      "Train Loss: 0.20884330570697784\n",
      "Train Loss: 0.20883412659168243\n",
      "Train Loss: 0.20881471037864685\n",
      "Train Loss: 0.2087908536195755\n",
      "Train Loss: 0.2087704986333847\n",
      "Train Loss: 0.2087724208831787\n",
      "Train Loss: 0.20876988768577576\n",
      "Train Loss: 0.2087530940771103\n",
      "Train Loss: 0.208731546998024\n",
      "Train Loss: 0.20871111750602722\n",
      "Train Loss: 0.20869100093841553\n",
      "Train Loss: 0.2086709588766098\n",
      "Train Loss: 0.20865501463413239\n",
      "Train Loss: 0.2086402326822281\n",
      "Train Loss: 0.20862261950969696\n",
      "Train Loss: 0.20860841870307922\n",
      "Train Loss: 0.20859688520431519\n",
      "Train Loss: 0.20859746634960175\n",
      "Train Loss: 0.20858949422836304\n",
      "Train Loss: 0.20857277512550354\n",
      "Train Loss: 0.20857107639312744\n",
      "Train Loss: 0.20855830609798431\n",
      "Train Loss: 0.2085449993610382\n",
      "Train Loss: 0.2085416167974472\n",
      "Train Loss: 0.20853380858898163\n",
      "Train Loss: 0.20851783454418182\n",
      "Train Loss: 0.2085144817829132\n",
      "Train Loss: 0.20851175487041473\n",
      "Train Loss: 0.2085055410861969\n",
      "Train Loss: 0.2085016816854477\n",
      "Train Loss: 0.20849449932575226\n",
      "Train Loss: 0.208479642868042\n",
      "Train Loss: 0.20846699178218842\n",
      "Train Loss: 0.20845463871955872\n",
      "Train Loss: 0.20844438672065735\n",
      "Train Loss: 0.20843003690242767\n",
      "Train Loss: 0.2084212303161621\n",
      "Train Loss: 0.20841240882873535\n",
      "Train Loss: 0.20839908719062805\n",
      "Train Loss: 0.2084040492773056\n",
      "Train Loss: 0.20840242505073547\n",
      "Train Loss: 0.20840159058570862\n",
      "Train Loss: 0.2084030658006668\n",
      "Train Loss: 0.20839764177799225\n",
      "Train Loss: 0.20839180052280426\n",
      "Train Loss: 0.20838141441345215\n",
      "Train Loss: 0.20836761593818665\n",
      "Train Loss: 0.20834901928901672\n",
      "Train Loss: 0.20833471417427063\n",
      "Train Loss: 0.20831811428070068\n",
      "Train Loss: 0.20830674469470978\n",
      "Train Loss: 0.20828892290592194\n",
      "Train Loss: 0.20826822519302368\n",
      "Train Loss: 0.2082531750202179\n",
      "Train Loss: 0.20823900401592255\n",
      "Train Loss: 0.20822778344154358\n",
      "Train Loss: 0.2082144170999527\n",
      "Train Loss: 0.2082001119852066\n",
      "Train Loss: 0.2081855982542038\n",
      "Train Loss: 0.20816540718078613\n",
      "Train Loss: 0.20815426111221313\n",
      "Train Loss: 0.2081371694803238\n",
      "Train Loss: 0.20811805129051208\n",
      "Train Loss: 0.20810078084468842\n",
      "Train Loss: 0.2080877721309662\n",
      "Train Loss: 0.20807887613773346\n",
      "Train Loss: 0.20806236565113068\n",
      "Train Loss: 0.2080426812171936\n",
      "Train Loss: 0.20802392065525055\n",
      "Train Loss: 0.20800650119781494\n",
      "Train Loss: 0.20798857510089874\n",
      "Train Loss: 0.2079746276140213\n",
      "Train Loss: 0.20796144008636475\n",
      "Train Loss: 0.2079513818025589\n",
      "Train Loss: 0.20793479681015015\n",
      "Train Loss: 0.20791597664356232\n",
      "Train Loss: 0.20789803564548492\n",
      "Train Loss: 0.20788152515888214\n",
      "Train Loss: 0.20786775648593903\n",
      "Train Loss: 0.2078588753938675\n",
      "Train Loss: 0.2078430950641632\n",
      "Train Loss: 0.20782504975795746\n",
      "Train Loss: 0.20780834555625916\n",
      "Train Loss: 0.2077944129705429\n",
      "Train Loss: 0.20778360962867737\n",
      "Train Loss: 0.20777925848960876\n",
      "Train Loss: 0.20777173340320587\n",
      "Train Loss: 0.2077590674161911\n",
      "Train Loss: 0.20775090157985687\n",
      "Train Loss: 0.2077474296092987\n",
      "Train Loss: 0.2077334225177765\n",
      "Train Loss: 0.20771653950214386\n",
      "Train Loss: 0.20769907534122467\n",
      "Train Loss: 0.20768362283706665\n",
      "Train Loss: 0.2076716423034668\n",
      "Train Loss: 0.20766857266426086\n",
      "Train Loss: 0.20765474438667297\n",
      "Train Loss: 0.20763571560382843\n",
      "Train Loss: 0.20761968195438385\n",
      "Train Loss: 0.20760416984558105\n",
      "Train Loss: 0.20759344100952148\n",
      "Train Loss: 0.20758835971355438\n",
      "Train Loss: 0.2075798660516739\n",
      "Train Loss: 0.20756232738494873\n",
      "Train Loss: 0.2075437754392624\n",
      "Train Loss: 0.20752635598182678\n",
      "Train Loss: 0.20751246809959412\n",
      "Train Loss: 0.20749855041503906\n",
      "Train Loss: 0.20748783648014069\n",
      "Train Loss: 0.20748098194599152\n",
      "Train Loss: 0.20747855305671692\n",
      "Train Loss: 0.2074679285287857\n",
      "Train Loss: 0.20745864510536194\n",
      "Train Loss: 0.20745916664600372\n",
      "Train Loss: 0.20745258033275604\n",
      "Train Loss: 0.2074376493692398\n",
      "Train Loss: 0.20743326842784882\n",
      "Train Loss: 0.2074260264635086\n",
      "Train Loss: 0.2074238508939743\n",
      "Train Loss: 0.2074170708656311\n",
      "Train Loss: 0.20740601420402527\n",
      "Train Loss: 0.2074090838432312\n",
      "Train Loss: 0.20739801228046417\n",
      "Train Loss: 0.2073892503976822\n",
      "Train Loss: 0.20737524330615997\n",
      "Train Loss: 0.20735785365104675\n",
      "Train Loss: 0.2073424607515335\n",
      "Train Loss: 0.20732657611370087\n",
      "Train Loss: 0.20731313526630402\n",
      "Train Loss: 0.2072998583316803\n",
      "Train Loss: 0.20728960633277893\n",
      "Train Loss: 0.2072766274213791\n",
      "Train Loss: 0.20726518332958221\n",
      "Train Loss: 0.2072616070508957\n",
      "Train Loss: 0.20725476741790771\n",
      "Train Loss: 0.20724767446517944\n",
      "Train Loss: 0.20723620057106018\n",
      "Train Loss: 0.20721955597400665\n",
      "Train Loss: 0.2072019875049591\n",
      "Train Loss: 0.20719216763973236\n",
      "Train Loss: 0.20718157291412354\n",
      "Train Loss: 0.20717845857143402\n",
      "Train Loss: 0.2071663737297058\n",
      "Train Loss: 0.20714978873729706\n",
      "Train Loss: 0.207137793302536\n",
      "Train Loss: 0.20712311565876007\n",
      "Train Loss: 0.20710903406143188\n",
      "Train Loss: 0.20709478855133057\n",
      "Train Loss: 0.20707881450653076\n",
      "Train Loss: 0.20706571638584137\n",
      "Train Loss: 0.20705388486385345\n",
      "Train Loss: 0.20704424381256104\n",
      "Train Loss: 0.20703552663326263\n",
      "Train Loss: 0.20703420042991638\n",
      "Train Loss: 0.20702743530273438\n",
      "Train Loss: 0.20702527463436127\n",
      "Train Loss: 0.2070130705833435\n",
      "Train Loss: 0.20699577033519745\n",
      "Train Loss: 0.20698300004005432\n",
      "Train Loss: 0.20697163045406342\n",
      "Train Loss: 0.2069648802280426\n",
      "Train Loss: 0.20700673758983612\n",
      "Train Loss: 0.20714449882507324\n",
      "Train Loss: 0.207196906208992\n",
      "Train Loss: 0.20719797909259796\n",
      "Train Loss: 0.2072141468524933\n",
      "Train Loss: 0.20723141729831696\n",
      "Train Loss: 0.20723503828048706\n",
      "Train Loss: 0.20723234117031097\n",
      "Train Loss: 0.20722563564777374\n",
      "Train Loss: 0.2072124481201172\n",
      "Train Loss: 0.20719997584819794\n",
      "Train Loss: 0.2071891576051712\n",
      "Train Loss: 0.20717398822307587\n",
      "Train Loss: 0.2071574479341507\n",
      "Train Loss: 0.20714545249938965\n",
      "Train Loss: 0.2071327418088913\n",
      "Train Loss: 0.20712226629257202\n",
      "Train Loss: 0.2071077674627304\n",
      "Train Loss: 0.20709556341171265\n",
      "Train Loss: 0.2070852518081665\n",
      "Train Loss: 0.20707105100154877\n",
      "Train Loss: 0.20706376433372498\n",
      "Train Loss: 0.2070581316947937\n",
      "Train Loss: 0.2070496380329132\n",
      "Train Loss: 0.20704060792922974\n",
      "Train Loss: 0.20702676475048065\n",
      "Train Loss: 0.20701096951961517\n",
      "Train Loss: 0.2069944441318512\n",
      "Train Loss: 0.20698067545890808\n",
      "Train Loss: 0.20696476101875305\n",
      "Train Loss: 0.20694956183433533\n",
      "Train Loss: 0.20693394541740417\n",
      "Train Loss: 0.20692463219165802\n",
      "Train Loss: 0.20691712200641632\n",
      "Train Loss: 0.206906259059906\n",
      "Train Loss: 0.20689789950847626\n",
      "Train Loss: 0.20688802003860474\n",
      "Train Loss: 0.2068760246038437\n",
      "Train Loss: 0.20686276257038116\n",
      "Train Loss: 0.20685409009456635\n",
      "Train Loss: 0.20684637129306793\n",
      "Train Loss: 0.2068423479795456\n",
      "Train Loss: 0.20683705806732178\n",
      "Train Loss: 0.2068275660276413\n",
      "Train Loss: 0.20682726800441742\n",
      "Train Loss: 0.20681576430797577\n",
      "Train Loss: 0.20680144429206848\n",
      "Train Loss: 0.20679065585136414\n",
      "Train Loss: 0.2067824900150299\n",
      "Train Loss: 0.20677423477172852\n",
      "Train Loss: 0.2067638337612152\n",
      "Train Loss: 0.2067568302154541\n",
      "Train Loss: 0.20674440264701843\n",
      "Train Loss: 0.2067294865846634\n",
      "Train Loss: 0.20671382546424866\n",
      "Train Loss: 0.20670263469219208\n",
      "Train Loss: 0.20669148862361908\n",
      "Train Loss: 0.206681489944458\n",
      "Train Loss: 0.2066795378923416\n",
      "Train Loss: 0.20666760206222534\n",
      "Train Loss: 0.20665456354618073\n",
      "Train Loss: 0.2066444754600525\n",
      "Train Loss: 0.2066388726234436\n",
      "Train Loss: 0.2066270262002945\n",
      "Train Loss: 0.2066107541322708\n",
      "Train Loss: 0.20659689605236053\n",
      "Train Loss: 0.2065894454717636\n",
      "Train Loss: 0.20657968521118164\n",
      "Train Loss: 0.2065657377243042\n",
      "Train Loss: 0.20655055344104767\n",
      "Train Loss: 0.20653802156448364\n",
      "Train Loss: 0.2065291404724121\n",
      "Train Loss: 0.20652711391448975\n",
      "Train Loss: 0.20652177929878235\n",
      "Train Loss: 0.20651639997959137\n",
      "Train Loss: 0.20650614798069\n",
      "Train Loss: 0.20649860799312592\n",
      "Train Loss: 0.20650212466716766\n",
      "Train Loss: 0.20649254322052002\n",
      "Train Loss: 0.20648042857646942\n",
      "Train Loss: 0.2065000832080841\n",
      "Train Loss: 0.20650242269039154\n",
      "Train Loss: 0.20649683475494385\n",
      "Train Loss: 0.20649176836013794\n",
      "Train Loss: 0.20648571848869324\n",
      "Train Loss: 0.20647519826889038\n",
      "Train Loss: 0.20648469030857086\n",
      "Train Loss: 0.20648106932640076\n",
      "Train Loss: 0.20647187530994415\n",
      "Train Loss: 0.2064671665430069\n",
      "Train Loss: 0.2064620703458786\n",
      "Train Loss: 0.20645231008529663\n",
      "Train Loss: 0.20643964409828186\n",
      "Train Loss: 0.2064289152622223\n",
      "Train Loss: 0.20642313361167908\n",
      "Train Loss: 0.2064148634672165\n",
      "Train Loss: 0.2064019739627838\n",
      "Train Loss: 0.20639149844646454\n",
      "Train Loss: 0.206384539604187\n",
      "Train Loss: 0.20637789368629456\n",
      "Train Loss: 0.2063705176115036\n",
      "Train Loss: 0.206363707780838\n",
      "Train Loss: 0.20635148882865906\n",
      "Train Loss: 0.20633721351623535\n",
      "Train Loss: 0.20632676780223846\n",
      "Train Loss: 0.20632033050060272\n",
      "Train Loss: 0.20631568133831024\n",
      "Train Loss: 0.20631027221679688\n",
      "Train Loss: 0.20630264282226562\n",
      "Train Loss: 0.20629757642745972\n",
      "Train Loss: 0.20628909766674042\n",
      "Train Loss: 0.2062823623418808\n",
      "Train Loss: 0.20627519488334656\n",
      "Train Loss: 0.20626845955848694\n",
      "Train Loss: 0.20625628530979156\n",
      "Train Loss: 0.2062440812587738\n",
      "Train Loss: 0.20623256266117096\n",
      "Train Loss: 0.2062244862318039\n",
      "Train Loss: 0.20621941983699799\n",
      "Train Loss: 0.20621678233146667\n",
      "Train Loss: 0.2062108963727951\n",
      "Train Loss: 0.2062024623155594\n",
      "Train Loss: 0.2061966061592102\n",
      "Train Loss: 0.20618556439876556\n",
      "Train Loss: 0.20617300271987915\n",
      "Train Loss: 0.20615985989570618\n",
      "Train Loss: 0.20614947378635406\n",
      "Train Loss: 0.20613890886306763\n",
      "Train Loss: 0.20612674951553345\n",
      "Train Loss: 0.2061212956905365\n",
      "Train Loss: 0.20611390471458435\n",
      "Train Loss: 0.20611391961574554\n",
      "Train Loss: 0.20611342787742615\n",
      "Train Loss: 0.2061101496219635\n",
      "Train Loss: 0.2061018943786621\n",
      "Train Loss: 0.20609739422798157\n",
      "Train Loss: 0.20609337091445923\n",
      "Train Loss: 0.20608265697956085\n",
      "Train Loss: 0.20606857538223267\n",
      "Train Loss: 0.20606011152267456\n",
      "Train Loss: 0.20605050027370453\n",
      "Train Loss: 0.20604245364665985\n",
      "Train Loss: 0.20604094862937927\n",
      "Train Loss: 0.20603778958320618\n",
      "Train Loss: 0.2060312181711197\n",
      "Train Loss: 0.2060355544090271\n",
      "Train Loss: 0.2060270607471466\n",
      "Train Loss: 0.20601491630077362\n",
      "Train Loss: 0.20600523054599762\n",
      "Train Loss: 0.20599310100078583\n",
      "Train Loss: 0.20598146319389343\n",
      "Train Loss: 0.20597237348556519\n",
      "Train Loss: 0.20596840977668762\n",
      "Train Loss: 0.2059634029865265\n",
      "Train Loss: 0.20595768094062805\n",
      "Train Loss: 0.20594805479049683\n",
      "Train Loss: 0.20593416690826416\n",
      "Train Loss: 0.20592251420021057\n",
      "Train Loss: 0.20591165125370026\n",
      "Train Loss: 0.20590177178382874\n",
      "Train Loss: 0.20589442551136017\n",
      "Train Loss: 0.20589129626750946\n",
      "Train Loss: 0.20588120818138123\n",
      "Train Loss: 0.2058706283569336\n",
      "Train Loss: 0.20586737990379333\n",
      "Train Loss: 0.20586052536964417\n",
      "Train Loss: 0.20585767924785614\n",
      "Train Loss: 0.20584890246391296\n",
      "Train Loss: 0.20584268867969513\n",
      "Train Loss: 0.20584358274936676\n",
      "Train Loss: 0.20583665370941162\n",
      "Train Loss: 0.20582883059978485\n",
      "Train Loss: 0.20582395792007446\n",
      "Train Loss: 0.20582525432109833\n",
      "Train Loss: 0.20582275092601776\n",
      "Train Loss: 0.20581625401973724\n",
      "Train Loss: 0.2058127373456955\n",
      "Train Loss: 0.20580722391605377\n",
      "Train Loss: 0.20580415427684784\n",
      "Train Loss: 0.2057972401380539\n",
      "Train Loss: 0.20579275488853455\n",
      "Train Loss: 0.2057855874300003\n",
      "Train Loss: 0.2057800143957138\n",
      "Train Loss: 0.20577426254749298\n",
      "Train Loss: 0.2057686150074005\n",
      "Train Loss: 0.205758199095726\n",
      "Train Loss: 0.20574608445167542\n",
      "Train Loss: 0.20573769509792328\n",
      "Train Loss: 0.2057294398546219\n",
      "Train Loss: 0.2057226300239563\n",
      "Train Loss: 0.20571711659431458\n",
      "Train Loss: 0.2057143598794937\n",
      "Train Loss: 0.2057110071182251\n",
      "Train Loss: 0.2057044357061386\n",
      "Train Loss: 0.20569828152656555\n",
      "Train Loss: 0.20569351315498352\n",
      "Train Loss: 0.20568892359733582\n",
      "Train Loss: 0.20568642020225525\n",
      "Train Loss: 0.20568214356899261\n",
      "Train Loss: 0.20567640662193298\n",
      "Train Loss: 0.205668643116951\n",
      "Train Loss: 0.2056645303964615\n",
      "Train Loss: 0.2056596577167511\n",
      "Train Loss: 0.2056550681591034\n",
      "Train Loss: 0.20564837753772736\n",
      "Train Loss: 0.20564289391040802\n",
      "Train Loss: 0.20563699305057526\n",
      "Train Loss: 0.20563004910945892\n",
      "Train Loss: 0.2056225836277008\n",
      "Train Loss: 0.20561237633228302\n",
      "Train Loss: 0.20560820400714874\n",
      "Train Loss: 0.205602765083313\n",
      "Train Loss: 0.2055935263633728\n",
      "Train Loss: 0.20559142529964447\n",
      "Train Loss: 0.20558789372444153\n",
      "Train Loss: 0.20557892322540283\n",
      "Train Loss: 0.20558179914951324\n",
      "Train Loss: 0.20557627081871033\n",
      "Train Loss: 0.20557071268558502\n",
      "Train Loss: 0.205564945936203\n",
      "Train Loss: 0.20555885136127472\n",
      "Train Loss: 0.20554819703102112\n",
      "Train Loss: 0.20553988218307495\n",
      "Train Loss: 0.20553451776504517\n",
      "Train Loss: 0.20552848279476166\n",
      "Train Loss: 0.20551741123199463\n",
      "Train Loss: 0.2055063396692276\n",
      "Train Loss: 0.20549577474594116\n",
      "Train Loss: 0.20549103617668152\n",
      "Train Loss: 0.20548580586910248\n",
      "Train Loss: 0.20548203587532043\n",
      "Train Loss: 0.2054729461669922\n",
      "Train Loss: 0.20546206831932068\n",
      "Train Loss: 0.20545095205307007\n",
      "Train Loss: 0.20544375479221344\n",
      "Train Loss: 0.20543643832206726\n",
      "Train Loss: 0.20543010532855988\n",
      "Train Loss: 0.20542439818382263\n",
      "Train Loss: 0.20541603863239288\n",
      "Train Loss: 0.2054063230752945\n",
      "Train Loss: 0.20539531111717224\n",
      "Train Loss: 0.20538532733917236\n",
      "Train Loss: 0.20537808537483215\n",
      "Train Loss: 0.2053719311952591\n",
      "Train Loss: 0.20536336302757263\n",
      "Train Loss: 0.2053566426038742\n",
      "Train Loss: 0.205347940325737\n",
      "Train Loss: 0.2053370177745819\n",
      "Train Loss: 0.20532970130443573\n",
      "Train Loss: 0.2053220123052597\n",
      "Train Loss: 0.20532090961933136\n",
      "Train Loss: 0.20531585812568665\n",
      "Train Loss: 0.20531374216079712\n",
      "Train Loss: 0.20531387627124786\n",
      "Train Loss: 0.2053101509809494\n",
      "Train Loss: 0.2053108662366867\n",
      "Train Loss: 0.2053050547838211\n",
      "Train Loss: 0.2052985429763794\n",
      "Train Loss: 0.20530065894126892\n",
      "Train Loss: 0.20529426634311676\n",
      "Train Loss: 0.20528250932693481\n",
      "Train Loss: 0.20527632534503937\n",
      "Train Loss: 0.20527979731559753\n",
      "Train Loss: 0.20527303218841553\n",
      "Train Loss: 0.20526254177093506\n",
      "Train Loss: 0.2052529901266098\n",
      "Train Loss: 0.20524545013904572\n",
      "Train Loss: 0.2052394151687622\n",
      "Train Loss: 0.20523348450660706\n",
      "Train Loss: 0.2052289843559265\n",
      "Train Loss: 0.20522579550743103\n",
      "Train Loss: 0.20522412657737732\n",
      "Train Loss: 0.20521824061870575\n",
      "Train Loss: 0.20521193742752075\n",
      "Train Loss: 0.2052132487297058\n",
      "Train Loss: 0.2052064836025238\n",
      "Train Loss: 0.20519521832466125\n",
      "Train Loss: 0.20518755912780762\n",
      "Train Loss: 0.20518197119235992\n",
      "Train Loss: 0.2051754742860794\n",
      "Train Loss: 0.20516961812973022\n",
      "Train Loss: 0.205163836479187\n",
      "Train Loss: 0.20515771210193634\n",
      "Train Loss: 0.2051583230495453\n",
      "Train Loss: 0.20515036582946777\n",
      "Train Loss: 0.20513971149921417\n",
      "Train Loss: 0.20512881875038147\n",
      "Train Loss: 0.20512305200099945\n",
      "Train Loss: 0.20512424409389496\n",
      "Train Loss: 0.20512178540229797\n",
      "Train Loss: 0.20511887967586517\n",
      "Train Loss: 0.20511315762996674\n",
      "Train Loss: 0.20510688424110413\n",
      "Train Loss: 0.2051093727350235\n",
      "Train Loss: 0.20510469377040863\n",
      "Train Loss: 0.2050981968641281\n",
      "Train Loss: 0.2051183581352234\n",
      "Train Loss: 0.20513862371444702\n",
      "Train Loss: 0.2051600217819214\n",
      "Train Loss: 0.20518985390663147\n",
      "Train Loss: 0.2051883190870285\n",
      "Train Loss: 0.20517776906490326\n",
      "Train Loss: 0.20516780018806458\n",
      "Train Loss: 0.20516180992126465\n",
      "Train Loss: 0.2051558941602707\n",
      "Train Loss: 0.20514672994613647\n",
      "Train Loss: 0.20513689517974854\n",
      "Train Loss: 0.2051314264535904\n",
      "Train Loss: 0.20512674748897552\n",
      "Train Loss: 0.20511695742607117\n",
      "Train Loss: 0.2051066756248474\n",
      "Train Loss: 0.20509958267211914\n",
      "Train Loss: 0.2050934135913849\n",
      "Train Loss: 0.20508909225463867\n",
      "Train Loss: 0.20507974922657013\n",
      "Train Loss: 0.20506952702999115\n",
      "Train Loss: 0.20505963265895844\n",
      "Train Loss: 0.20504917204380035\n",
      "Train Loss: 0.20503972470760345\n",
      "Train Loss: 0.2050309181213379\n",
      "Train Loss: 0.2050214409828186\n",
      "Train Loss: 0.2050122320652008\n",
      "Train Loss: 0.20500533282756805\n",
      "Train Loss: 0.20500317215919495\n",
      "Train Loss: 0.20499584078788757\n",
      "Train Loss: 0.2049860954284668\n",
      "Train Loss: 0.20498047769069672\n",
      "Train Loss: 0.2049761712551117\n",
      "Train Loss: 0.2049737125635147\n",
      "Train Loss: 0.20496594905853271\n",
      "Train Loss: 0.20496155321598053\n",
      "Train Loss: 0.20496182143688202\n",
      "Train Loss: 0.20495378971099854\n",
      "Train Loss: 0.20494569838047028\n",
      "Train Loss: 0.20493872463703156\n",
      "Train Loss: 0.20493292808532715\n",
      "Train Loss: 0.20493096113204956\n",
      "Train Loss: 0.20492352545261383\n",
      "Train Loss: 0.20491409301757812\n",
      "Train Loss: 0.20490624010562897\n",
      "Train Loss: 0.20490039885044098\n",
      "Train Loss: 0.20489585399627686\n",
      "Train Loss: 0.20489418506622314\n",
      "Train Loss: 0.20489069819450378\n",
      "Train Loss: 0.20488998293876648\n",
      "Train Loss: 0.2048831582069397\n",
      "Train Loss: 0.20487286150455475\n",
      "Train Loss: 0.20486679673194885\n",
      "Train Loss: 0.20486457645893097\n",
      "Train Loss: 0.2048591822385788\n",
      "Train Loss: 0.20485039055347443\n",
      "Train Loss: 0.20484229922294617\n",
      "Train Loss: 0.2048337310552597\n",
      "Train Loss: 0.2048262655735016\n",
      "Train Loss: 0.2048204094171524\n",
      "Train Loss: 0.20481310784816742\n",
      "Train Loss: 0.2048112154006958\n",
      "Train Loss: 0.2048109471797943\n",
      "Train Loss: 0.20480799674987793\n",
      "Train Loss: 0.20480437576770782\n",
      "Train Loss: 0.20480051636695862\n",
      "Train Loss: 0.2047966718673706\n",
      "Train Loss: 0.2047920525074005\n",
      "Train Loss: 0.2047911286354065\n",
      "Train Loss: 0.20478954911231995\n",
      "Train Loss: 0.20478300750255585\n",
      "Train Loss: 0.2047877162694931\n",
      "Train Loss: 0.2047816962003708\n",
      "Train Loss: 0.20477266609668732\n",
      "Train Loss: 0.20476506650447845\n",
      "Train Loss: 0.20475877821445465\n",
      "Train Loss: 0.2047523856163025\n",
      "Train Loss: 0.204745814204216\n",
      "Train Loss: 0.20475949347019196\n",
      "Train Loss: 0.2047782987356186\n",
      "Train Loss: 0.2047988325357437\n",
      "Train Loss: 0.20483000576496124\n",
      "Train Loss: 0.20482777059078217\n",
      "Train Loss: 0.2048177421092987\n",
      "Train Loss: 0.20480772852897644\n",
      "Train Loss: 0.20480036735534668\n",
      "Train Loss: 0.20479582250118256\n",
      "Train Loss: 0.20478801429271698\n",
      "Train Loss: 0.20477789640426636\n",
      "Train Loss: 0.20477010309696198\n",
      "Train Loss: 0.20476172864437103\n",
      "Train Loss: 0.20475231111049652\n",
      "Train Loss: 0.20474354922771454\n",
      "Train Loss: 0.2047353833913803\n",
      "Train Loss: 0.2047267109155655\n",
      "Train Loss: 0.2047170251607895\n",
      "Train Loss: 0.2047078162431717\n",
      "Train Loss: 0.20470257103443146\n",
      "Train Loss: 0.20469693839550018\n",
      "Train Loss: 0.20469315350055695\n",
      "Train Loss: 0.20469383895397186\n",
      "Train Loss: 0.20469233393669128\n",
      "Train Loss: 0.2046867460012436\n",
      "Train Loss: 0.20468562841415405\n",
      "Train Loss: 0.20468489825725555\n",
      "Train Loss: 0.20467771589756012\n",
      "Train Loss: 0.20466864109039307\n",
      "Train Loss: 0.2046661227941513\n",
      "Train Loss: 0.20466387271881104\n",
      "Train Loss: 0.2046583741903305\n",
      "Train Loss: 0.204649418592453\n",
      "Train Loss: 0.20464260876178741\n",
      "Train Loss: 0.20463941991329193\n",
      "Train Loss: 0.20463351905345917\n",
      "Train Loss: 0.20462732017040253\n",
      "Train Loss: 0.20462319254875183\n",
      "Train Loss: 0.20461967587471008\n",
      "Train Loss: 0.20461255311965942\n",
      "Train Loss: 0.2046044021844864\n",
      "Train Loss: 0.20460066199302673\n",
      "Train Loss: 0.20459888875484467\n",
      "Train Loss: 0.20459231734275818\n",
      "Train Loss: 0.2045840322971344\n",
      "Train Loss: 0.2045849859714508\n",
      "Train Loss: 0.20457974076271057\n",
      "Train Loss: 0.20457574725151062\n",
      "Train Loss: 0.20457413792610168\n",
      "Train Loss: 0.20456703007221222\n",
      "Train Loss: 0.20455877482891083\n",
      "Train Loss: 0.20455023646354675\n",
      "Train Loss: 0.20454181730747223\n",
      "Train Loss: 0.20453567802906036\n",
      "Train Loss: 0.20453083515167236\n",
      "Train Loss: 0.20452824234962463\n",
      "Train Loss: 0.20452718436717987\n",
      "Train Loss: 0.20452287793159485\n",
      "Train Loss: 0.20452061295509338\n",
      "Train Loss: 0.20451374351978302\n",
      "Train Loss: 0.20450648665428162\n",
      "Train Loss: 0.2044999599456787\n",
      "Train Loss: 0.20449411869049072\n",
      "Train Loss: 0.2044883370399475\n",
      "Train Loss: 0.20448361337184906\n",
      "Train Loss: 0.20447836816310883\n",
      "Train Loss: 0.2044752985239029\n",
      "Train Loss: 0.20447520911693573\n",
      "Train Loss: 0.2044709473848343\n",
      "Train Loss: 0.20446224510669708\n",
      "Train Loss: 0.2044580727815628\n",
      "Train Loss: 0.2044527232646942\n",
      "Train Loss: 0.20444715023040771\n",
      "Train Loss: 0.20444051921367645\n",
      "Train Loss: 0.20443673431873322\n",
      "Train Loss: 0.20443332195281982\n",
      "Train Loss: 0.20442873239517212\n",
      "Train Loss: 0.20442649722099304\n",
      "Train Loss: 0.2044205218553543\n",
      "Train Loss: 0.20441262423992157\n",
      "Train Loss: 0.2044050395488739\n",
      "Train Loss: 0.20439757406711578\n",
      "Train Loss: 0.2043902426958084\n",
      "Train Loss: 0.20438252389431\n",
      "Train Loss: 0.20437343418598175\n",
      "Train Loss: 0.20436570048332214\n",
      "Train Loss: 0.2043599933385849\n",
      "Train Loss: 0.20435410737991333\n",
      "Train Loss: 0.2043474167585373\n",
      "Train Loss: 0.20434260368347168\n",
      "Train Loss: 0.20434273779392242\n",
      "Train Loss: 0.20433703064918518\n",
      "Train Loss: 0.20433181524276733\n",
      "Train Loss: 0.20432978868484497\n",
      "Train Loss: 0.2043284922838211\n",
      "Train Loss: 0.2043326497077942\n",
      "Train Loss: 0.2043268233537674\n",
      "Train Loss: 0.20431815087795258\n",
      "Train Loss: 0.20431041717529297\n",
      "Train Loss: 0.204304039478302\n",
      "Train Loss: 0.2043004333972931\n",
      "Train Loss: 0.20429310202598572\n",
      "Train Loss: 0.20428700745105743\n",
      "Train Loss: 0.20428259670734406\n",
      "Train Loss: 0.20427823066711426\n",
      "Train Loss: 0.20427198708057404\n",
      "Train Loss: 0.20426733791828156\n",
      "Train Loss: 0.20427271723747253\n",
      "Train Loss: 0.20426979660987854\n",
      "Train Loss: 0.20426888763904572\n",
      "Train Loss: 0.20426402986049652\n",
      "Train Loss: 0.20425637066364288\n",
      "Train Loss: 0.20425155758857727\n",
      "Train Loss: 0.20424723625183105\n",
      "Train Loss: 0.2042439877986908\n",
      "Train Loss: 0.20424361526966095\n",
      "Train Loss: 0.20424789190292358\n",
      "Train Loss: 0.20424386858940125\n",
      "Train Loss: 0.2042396068572998\n",
      "Train Loss: 0.20424054563045502\n",
      "Train Loss: 0.20423877239227295\n",
      "Train Loss: 0.20423658192157745\n",
      "Train Loss: 0.20423702895641327\n",
      "Train Loss: 0.20423561334609985\n",
      "Train Loss: 0.20423367619514465\n",
      "Train Loss: 0.20424336194992065\n",
      "Train Loss: 0.20425352454185486\n",
      "Train Loss: 0.20426999032497406\n",
      "Train Loss: 0.20427833497524261\n",
      "Train Loss: 0.2042963057756424\n",
      "Train Loss: 0.20431531965732574\n",
      "Train Loss: 0.20431891083717346\n",
      "Train Loss: 0.20431654155254364\n",
      "Train Loss: 0.20431451499462128\n",
      "Train Loss: 0.20431192219257355\n",
      "Train Loss: 0.20430444180965424\n",
      "Train Loss: 0.20429882407188416\n",
      "Train Loss: 0.20430298149585724\n",
      "Train Loss: 0.204307422041893\n",
      "Train Loss: 0.20432114601135254\n",
      "Train Loss: 0.20433765649795532\n",
      "Train Loss: 0.20433983206748962\n",
      "Train Loss: 0.2043364942073822\n",
      "Train Loss: 0.20435068011283875\n",
      "Train Loss: 0.2043703943490982\n",
      "Train Loss: 0.2043711543083191\n",
      "Train Loss: 0.2043653130531311\n",
      "Train Loss: 0.2043619602918625\n",
      "Train Loss: 0.20435847342014313\n",
      "Train Loss: 0.20435887575149536\n",
      "Train Loss: 0.2043527364730835\n",
      "Train Loss: 0.20434504747390747\n",
      "Train Loss: 0.20434370636940002\n",
      "Train Loss: 0.2043403536081314\n",
      "Train Loss: 0.20433855056762695\n",
      "Train Loss: 0.2043340653181076\n",
      "Train Loss: 0.2043260931968689\n",
      "Train Loss: 0.20431803166866302\n",
      "Train Loss: 0.2043098658323288\n",
      "Train Loss: 0.20430156588554382\n",
      "Train Loss: 0.2042931765317917\n",
      "Train Loss: 0.20428496599197388\n",
      "Train Loss: 0.20428410172462463\n",
      "Train Loss: 0.20427744090557098\n",
      "Train Loss: 0.20427007973194122\n",
      "Train Loss: 0.20426739752292633\n",
      "Train Loss: 0.2042626142501831\n",
      "Train Loss: 0.20425501465797424\n",
      "Train Loss: 0.2042507529258728\n",
      "Train Loss: 0.20424608886241913\n",
      "Train Loss: 0.20424021780490875\n",
      "Train Loss: 0.2042326182126999\n",
      "Train Loss: 0.20422694087028503\n",
      "Train Loss: 0.2042197734117508\n",
      "Train Loss: 0.20421288907527924\n",
      "Train Loss: 0.20420539379119873\n",
      "Train Loss: 0.20419766008853912\n",
      "Train Loss: 0.20418979227542877\n",
      "Train Loss: 0.20418250560760498\n",
      "Train Loss: 0.20417505502700806\n",
      "Train Loss: 0.2041701078414917\n",
      "Train Loss: 0.20416587591171265\n",
      "Train Loss: 0.20416194200515747\n",
      "Train Loss: 0.20415878295898438\n",
      "Train Loss: 0.20415173470973969\n",
      "Train Loss: 0.20414714515209198\n",
      "Train Loss: 0.20414739847183228\n",
      "Train Loss: 0.20414143800735474\n",
      "Train Loss: 0.20413316786289215\n",
      "Train Loss: 0.20412693917751312\n",
      "Train Loss: 0.20412161946296692\n",
      "Train Loss: 0.20411935448646545\n",
      "Train Loss: 0.20411334931850433\n",
      "Train Loss: 0.20410583913326263\n",
      "Train Loss: 0.20410123467445374\n",
      "Train Loss: 0.20409592986106873\n",
      "Train Loss: 0.20409096777439117\n",
      "Train Loss: 0.20408886671066284\n",
      "Train Loss: 0.20408622920513153\n",
      "Train Loss: 0.20408301055431366\n",
      "Train Loss: 0.20408247411251068\n",
      "Train Loss: 0.20408150553703308\n",
      "Train Loss: 0.20407968759536743\n",
      "Train Loss: 0.20408129692077637\n",
      "Train Loss: 0.20407727360725403\n",
      "Train Loss: 0.2040693610906601\n",
      "Train Loss: 0.20406439900398254\n",
      "Train Loss: 0.2040591835975647\n",
      "Train Loss: 0.20405560731887817\n",
      "Train Loss: 0.20405517518520355\n",
      "Train Loss: 0.20405231416225433\n",
      "Train Loss: 0.2040480077266693\n",
      "Train Loss: 0.2040422260761261\n",
      "Train Loss: 0.2040376514196396\n",
      "Train Loss: 0.20403245091438293\n",
      "Train Loss: 0.20402590930461884\n",
      "Train Loss: 0.20401841402053833\n",
      "Train Loss: 0.2040139138698578\n",
      "Train Loss: 0.20401188731193542\n",
      "Train Loss: 0.20401425659656525\n",
      "Train Loss: 0.2040124088525772\n",
      "Train Loss: 0.20400896668434143\n",
      "Train Loss: 0.20400786399841309\n",
      "Train Loss: 0.20400477945804596\n",
      "Train Loss: 0.20400594174861908\n",
      "Train Loss: 0.20400410890579224\n",
      "Train Loss: 0.204000785946846\n",
      "Train Loss: 0.20400051772594452\n",
      "Train Loss: 0.20399515330791473\n",
      "Train Loss: 0.20398885011672974\n",
      "Train Loss: 0.20398296415805817\n",
      "Train Loss: 0.20397773385047913\n",
      "Train Loss: 0.20397184789180756\n",
      "Train Loss: 0.20396879315376282\n",
      "Train Loss: 0.20396776497364044\n",
      "Train Loss: 0.20396187901496887\n",
      "Train Loss: 0.20395566523075104\n",
      "Train Loss: 0.2039516270160675\n",
      "Train Loss: 0.2039451003074646\n",
      "Train Loss: 0.2039390653371811\n",
      "Train Loss: 0.2039327174425125\n",
      "Train Loss: 0.20392799377441406\n",
      "Train Loss: 0.20392747223377228\n",
      "Train Loss: 0.20392534136772156\n",
      "Train Loss: 0.20392324030399323\n",
      "Train Loss: 0.20391955971717834\n",
      "Train Loss: 0.20391255617141724\n",
      "Train Loss: 0.2039051204919815\n",
      "Train Loss: 0.20389962196350098\n",
      "Train Loss: 0.20389452576637268\n",
      "Train Loss: 0.20388978719711304\n",
      "Train Loss: 0.20388464629650116\n",
      "Train Loss: 0.20387998223304749\n",
      "Train Loss: 0.20387500524520874\n",
      "Train Loss: 0.20387046039104462\n",
      "Train Loss: 0.20386700332164764\n",
      "Train Loss: 0.20386433601379395\n",
      "Train Loss: 0.20386476814746857\n",
      "Train Loss: 0.20385950803756714\n",
      "Train Loss: 0.20385660231113434\n",
      "Train Loss: 0.2038576751947403\n",
      "Train Loss: 0.20385590195655823\n",
      "Train Loss: 0.2038562148809433\n",
      "Train Loss: 0.20385101437568665\n",
      "Train Loss: 0.20384559035301208\n",
      "Train Loss: 0.2038433700799942\n",
      "Train Loss: 0.20384222269058228\n",
      "Train Loss: 0.20383906364440918\n",
      "Train Loss: 0.20383773744106293\n",
      "Train Loss: 0.2038334459066391\n",
      "Train Loss: 0.20382779836654663\n",
      "Train Loss: 0.20382177829742432\n",
      "Train Loss: 0.203815758228302\n",
      "Train Loss: 0.20381323993206024\n",
      "Train Loss: 0.20381219685077667\n",
      "Train Loss: 0.20381180942058563\n",
      "Train Loss: 0.2038094699382782\n",
      "Train Loss: 0.2038072645664215\n",
      "Train Loss: 0.20380567014217377\n",
      "Train Loss: 0.20380251109600067\n",
      "Train Loss: 0.2037990391254425\n",
      "Train Loss: 0.20379279553890228\n",
      "Train Loss: 0.20378829538822174\n",
      "Train Loss: 0.20378951728343964\n",
      "Train Loss: 0.2037864625453949\n",
      "Train Loss: 0.20378047227859497\n",
      "Train Loss: 0.20377451181411743\n",
      "Train Loss: 0.20377212762832642\n",
      "Train Loss: 0.20377443730831146\n",
      "Train Loss: 0.20377101004123688\n",
      "Train Loss: 0.20376382768154144\n",
      "Train Loss: 0.20376022160053253\n",
      "Train Loss: 0.20375873148441315\n",
      "Train Loss: 0.203761026263237\n",
      "Train Loss: 0.20375773310661316\n",
      "Train Loss: 0.2037506252527237\n",
      "Train Loss: 0.20374687016010284\n",
      "Train Loss: 0.20374222099781036\n",
      "Train Loss: 0.20373791456222534\n",
      "Train Loss: 0.20373483002185822\n",
      "Train Loss: 0.20373541116714478\n",
      "Train Loss: 0.20373377203941345\n",
      "Train Loss: 0.20373038947582245\n",
      "Train Loss: 0.20373037457466125\n",
      "Train Loss: 0.2037259191274643\n",
      "Train Loss: 0.20372197031974792\n",
      "Train Loss: 0.2037205696105957\n",
      "Train Loss: 0.2037188559770584\n",
      "Train Loss: 0.20371758937835693\n",
      "Train Loss: 0.203715980052948\n",
      "Train Loss: 0.20371416211128235\n",
      "Train Loss: 0.2037128061056137\n",
      "Train Loss: 0.20371153950691223\n",
      "Train Loss: 0.20370833575725555\n",
      "Train Loss: 0.20370596647262573\n",
      "Train Loss: 0.20370356738567352\n",
      "Train Loss: 0.20370346307754517\n",
      "Train Loss: 0.20370255410671234\n",
      "Train Loss: 0.20370040833950043\n",
      "Train Loss: 0.2037024199962616\n",
      "Train Loss: 0.20369787514209747\n",
      "Train Loss: 0.2036908119916916\n",
      "Train Loss: 0.2036862075328827\n",
      "Train Loss: 0.20368151366710663\n",
      "Train Loss: 0.2036786526441574\n",
      "Train Loss: 0.20368045568466187\n",
      "Train Loss: 0.20367608964443207\n",
      "Train Loss: 0.20367003977298737\n",
      "Train Loss: 0.2036684900522232\n",
      "Train Loss: 0.20366671681404114\n",
      "Train Loss: 0.20366868376731873\n",
      "Train Loss: 0.20366686582565308\n",
      "Train Loss: 0.20366278290748596\n",
      "Train Loss: 0.20366214215755463\n",
      "Train Loss: 0.20366162061691284\n",
      "Train Loss: 0.20365802943706512\n",
      "Train Loss: 0.20365245640277863\n",
      "Train Loss: 0.2036474198102951\n",
      "Train Loss: 0.20364461839199066\n",
      "Train Loss: 0.20364464819431305\n",
      "Train Loss: 0.20364312827587128\n",
      "Train Loss: 0.2036396712064743\n",
      "Train Loss: 0.20365013182163239\n",
      "Train Loss: 0.20365232229232788\n",
      "Train Loss: 0.20365384221076965\n",
      "Train Loss: 0.20365776121616364\n",
      "Train Loss: 0.20365630090236664\n",
      "Train Loss: 0.20365287363529205\n",
      "Train Loss: 0.20365124940872192\n",
      "Train Loss: 0.203648641705513\n",
      "Train Loss: 0.2036455273628235\n",
      "Train Loss: 0.20364291965961456\n",
      "Train Loss: 0.20363758504390717\n",
      "Train Loss: 0.20363393425941467\n",
      "Train Loss: 0.20363137125968933\n",
      "Train Loss: 0.20362553000450134\n",
      "Train Loss: 0.20361840724945068\n",
      "Train Loss: 0.20361411571502686\n",
      "Train Loss: 0.2036110907793045\n",
      "Train Loss: 0.20360904932022095\n",
      "Train Loss: 0.20360662043094635\n",
      "Train Loss: 0.20360125601291656\n",
      "Train Loss: 0.20359520614147186\n",
      "Train Loss: 0.20358984172344208\n",
      "Train Loss: 0.20358844101428986\n",
      "Train Loss: 0.20358723402023315\n",
      "Train Loss: 0.2035820633172989\n",
      "Train Loss: 0.20357774198055267\n",
      "Train Loss: 0.20357519388198853\n",
      "Train Loss: 0.20357485115528107\n",
      "Train Loss: 0.20357279479503632\n",
      "Train Loss: 0.20356939733028412\n",
      "Train Loss: 0.20356835424900055\n",
      "Train Loss: 0.20356813073158264\n",
      "Train Loss: 0.20356443524360657\n",
      "Train Loss: 0.2035626322031021\n",
      "Train Loss: 0.20356059074401855\n",
      "Train Loss: 0.2035573422908783\n",
      "Train Loss: 0.20355315506458282\n",
      "Train Loss: 0.2035508006811142\n",
      "Train Loss: 0.20354819297790527\n",
      "Train Loss: 0.20354564487934113\n",
      "Train Loss: 0.2035435140132904\n",
      "Train Loss: 0.20353750884532928\n",
      "Train Loss: 0.2035321742296219\n",
      "Train Loss: 0.20352816581726074\n",
      "Train Loss: 0.20352675020694733\n",
      "Train Loss: 0.2035239189863205\n",
      "Train Loss: 0.20352202653884888\n",
      "Train Loss: 0.20351985096931458\n",
      "Train Loss: 0.20351769030094147\n",
      "Train Loss: 0.20351186394691467\n",
      "Train Loss: 0.2035067230463028\n",
      "Train Loss: 0.2035047709941864\n",
      "Train Loss: 0.20350231230258942\n",
      "Train Loss: 0.20349690318107605\n",
      "Train Loss: 0.20349107682704926\n",
      "Train Loss: 0.20349039137363434\n",
      "Train Loss: 0.20348726212978363\n",
      "Train Loss: 0.20348559319972992\n",
      "Train Loss: 0.2034830003976822\n",
      "Train Loss: 0.20348112285137177\n",
      "Train Loss: 0.20348046720027924\n",
      "Train Loss: 0.20347630977630615\n",
      "Train Loss: 0.2034703493118286\n",
      "Train Loss: 0.20346398651599884\n",
      "Train Loss: 0.2034587860107422\n",
      "Train Loss: 0.20345301926136017\n",
      "Train Loss: 0.20344726741313934\n",
      "Train Loss: 0.2034415900707245\n",
      "Train Loss: 0.20343561470508575\n",
      "Train Loss: 0.20343174040317535\n",
      "Train Loss: 0.20342814922332764\n",
      "Train Loss: 0.20342522859573364\n",
      "Train Loss: 0.20342719554901123\n",
      "Train Loss: 0.2034231722354889\n",
      "Train Loss: 0.20341724157333374\n",
      "Train Loss: 0.2034139633178711\n",
      "Train Loss: 0.20340965688228607\n",
      "Train Loss: 0.2034057080745697\n",
      "Train Loss: 0.20340228080749512\n",
      "Train Loss: 0.2033994495868683\n",
      "Train Loss: 0.20339909195899963\n",
      "Train Loss: 0.20339785516262054\n",
      "Train Loss: 0.20339642465114594\n",
      "Train Loss: 0.2033974528312683\n",
      "Train Loss: 0.20339474081993103\n",
      "Train Loss: 0.2033931165933609\n",
      "Train Loss: 0.20339155197143555\n",
      "Train Loss: 0.20339161157608032\n",
      "Train Loss: 0.20338685810565948\n",
      "Train Loss: 0.20338056981563568\n",
      "Train Loss: 0.20337747037410736\n",
      "Train Loss: 0.2033759206533432\n",
      "Train Loss: 0.2033735066652298\n",
      "Train Loss: 0.20337191224098206\n",
      "Train Loss: 0.20336996018886566\n",
      "Train Loss: 0.20336395502090454\n",
      "Train Loss: 0.2033575475215912\n",
      "Train Loss: 0.20335623621940613\n",
      "Train Loss: 0.20335492491722107\n",
      "Train Loss: 0.2033587545156479\n",
      "Train Loss: 0.20336589217185974\n",
      "Train Loss: 0.20338629186153412\n",
      "Train Loss: 0.20342203974723816\n",
      "Train Loss: 0.20345459878444672\n",
      "Train Loss: 0.20349206030368805\n",
      "Train Loss: 0.20353776216506958\n",
      "Train Loss: 0.20355351269245148\n",
      "Train Loss: 0.20355278253555298\n",
      "Train Loss: 0.2035587877035141\n",
      "Train Loss: 0.20356804132461548\n",
      "Train Loss: 0.20356670022010803\n",
      "Train Loss: 0.20356065034866333\n",
      "Train Loss: 0.20355768501758575\n",
      "Train Loss: 0.20355218648910522\n",
      "Train Loss: 0.20354723930358887\n",
      "Train Loss: 0.20354294776916504\n",
      "Train Loss: 0.20353765785694122\n",
      "Train Loss: 0.20353901386260986\n",
      "Train Loss: 0.20354104042053223\n",
      "Train Loss: 0.2035478800535202\n",
      "Train Loss: 0.2035522609949112\n",
      "Train Loss: 0.20355495810508728\n",
      "Train Loss: 0.20355547964572906\n",
      "Train Loss: 0.2035587579011917\n",
      "Train Loss: 0.2035612314939499\n",
      "Train Loss: 0.20356564223766327\n",
      "Train Loss: 0.20356598496437073\n",
      "Train Loss: 0.20356690883636475\n",
      "Train Loss: 0.2035682052373886\n",
      "Train Loss: 0.20356915891170502\n",
      "Train Loss: 0.20357109606266022\n",
      "Train Loss: 0.20357021689414978\n",
      "Train Loss: 0.2035684436559677\n",
      "Train Loss: 0.20357243716716766\n",
      "Train Loss: 0.20357464253902435\n",
      "Train Loss: 0.20357932150363922\n",
      "Train Loss: 0.20357945561408997\n",
      "Train Loss: 0.20357830822467804\n",
      "Train Loss: 0.20357532799243927\n",
      "Train Loss: 0.20357948541641235\n",
      "Train Loss: 0.20358186960220337\n",
      "Train Loss: 0.20357930660247803\n",
      "Train Loss: 0.20357587933540344\n",
      "Train Loss: 0.2035774141550064\n",
      "Train Loss: 0.2035810500383377\n",
      "Train Loss: 0.20358341932296753\n",
      "Train Loss: 0.20358365774154663\n",
      "Train Loss: 0.20358432829380035\n",
      "Train Loss: 0.20358461141586304\n",
      "Train Loss: 0.2035830318927765\n",
      "Train Loss: 0.2035788893699646\n",
      "Train Loss: 0.20358100533485413\n",
      "Train Loss: 0.2035841941833496\n",
      "Train Loss: 0.20358258485794067\n",
      "Train Loss: 0.20357784628868103\n",
      "Train Loss: 0.2035762220621109\n",
      "Train Loss: 0.20357370376586914\n",
      "Train Loss: 0.20357266068458557\n",
      "Train Loss: 0.20357169210910797\n",
      "Train Loss: 0.20357468724250793\n",
      "Train Loss: 0.20357507467269897\n",
      "Train Loss: 0.2035750299692154\n",
      "Train Loss: 0.20357343554496765\n",
      "Train Loss: 0.2035747915506363\n",
      "Train Loss: 0.20357868075370789\n",
      "Train Loss: 0.20357678830623627\n",
      "Train Loss: 0.2035716325044632\n",
      "Train Loss: 0.2035701870918274\n",
      "Train Loss: 0.20357081294059753\n",
      "Train Loss: 0.20357394218444824\n",
      "Train Loss: 0.203570157289505\n",
      "Train Loss: 0.20357166230678558\n",
      "Train Loss: 0.20357263088226318\n",
      "Train Loss: 0.20357538759708405\n",
      "Train Loss: 0.2035752385854721\n",
      "Train Loss: 0.20357461273670197\n",
      "Train Loss: 0.2035728543996811\n",
      "Train Loss: 0.20357447862625122\n",
      "Train Loss: 0.20357508957386017\n",
      "Train Loss: 0.2035745233297348\n",
      "Train Loss: 0.20357200503349304\n",
      "Train Loss: 0.20357221364974976\n",
      "Train Loss: 0.20357298851013184\n",
      "Train Loss: 0.20357264578342438\n",
      "Train Loss: 0.2035709172487259\n",
      "Train Loss: 0.20357228815555573\n",
      "Train Loss: 0.2035738080739975\n",
      "Train Loss: 0.2035762071609497\n",
      "Train Loss: 0.20357587933540344\n",
      "Train Loss: 0.20357440412044525\n",
      "Train Loss: 0.203571617603302\n",
      "Train Loss: 0.20357339084148407\n",
      "Train Loss: 0.20357570052146912\n",
      "Train Loss: 0.2035730630159378\n",
      "Train Loss: 0.2035694420337677\n",
      "Train Loss: 0.2035694718360901\n",
      "Train Loss: 0.20356912910938263\n",
      "Train Loss: 0.20356927812099457\n",
      "Train Loss: 0.20356802642345428\n",
      "Train Loss: 0.20356802642345428\n",
      "Train Loss: 0.20356670022010803\n",
      "Train Loss: 0.20356670022010803\n",
      "Train Loss: 0.2035662978887558\n",
      "Train Loss: 0.20356407761573792\n",
      "Train Loss: 0.2035597860813141\n",
      "Train Loss: 0.20356176793575287\n",
      "Train Loss: 0.20356440544128418\n",
      "Train Loss: 0.20356117188930511\n",
      "Train Loss: 0.20355622470378876\n",
      "Train Loss: 0.20355863869190216\n",
      "Train Loss: 0.20356082916259766\n",
      "Train Loss: 0.20355898141860962\n",
      "Train Loss: 0.20355458557605743\n",
      "Train Loss: 0.20355577766895294\n",
      "Train Loss: 0.20355898141860962\n",
      "Train Loss: 0.20356106758117676\n",
      "Train Loss: 0.20356029272079468\n",
      "Train Loss: 0.20356009900569916\n",
      "Train Loss: 0.20355889201164246\n",
      "Train Loss: 0.20355801284313202\n",
      "Train Loss: 0.20355691015720367\n",
      "Train Loss: 0.20355767011642456\n",
      "Train Loss: 0.20355938374996185\n",
      "Train Loss: 0.2035585343837738\n",
      "Train Loss: 0.20355434715747833\n",
      "Train Loss: 0.20355413854122162\n",
      "Train Loss: 0.20355206727981567\n",
      "Train Loss: 0.20355498790740967\n",
      "Train Loss: 0.20355458557605743\n",
      "Train Loss: 0.2035532295703888\n",
      "Train Loss: 0.20355087518692017\n",
      "Train Loss: 0.20355267822742462\n",
      "Train Loss: 0.2035544514656067\n",
      "Train Loss: 0.20355340838432312\n",
      "Train Loss: 0.20354856550693512\n",
      "Train Loss: 0.20355170965194702\n",
      "Train Loss: 0.2035553753376007\n",
      "Train Loss: 0.2035529464483261\n",
      "Train Loss: 0.203550785779953\n",
      "Train Loss: 0.20355196297168732\n",
      "Train Loss: 0.20355316996574402\n",
      "Train Loss: 0.2035505771636963\n",
      "Train Loss: 0.20354525744915009\n",
      "Train Loss: 0.20354555547237396\n",
      "Train Loss: 0.20354491472244263\n",
      "Train Loss: 0.20354649424552917\n",
      "Train Loss: 0.20354673266410828\n",
      "Train Loss: 0.2035447508096695\n",
      "Train Loss: 0.20354080200195312\n",
      "Train Loss: 0.20354099571704865\n",
      "Train Loss: 0.20354296267032623\n",
      "Train Loss: 0.2035447657108307\n",
      "Train Loss: 0.20354461669921875\n",
      "Train Loss: 0.20354484021663666\n",
      "Train Loss: 0.20354460179805756\n",
      "Train Loss: 0.20354627072811127\n",
      "Train Loss: 0.20354564487934113\n",
      "Train Loss: 0.20354525744915009\n",
      "Train Loss: 0.2035433053970337\n",
      "Train Loss: 0.20354397594928741\n",
      "Train Loss: 0.20354357361793518\n",
      "Train Loss: 0.20354554057121277\n",
      "Train Loss: 0.2035454362630844\n",
      "Train Loss: 0.20354515314102173\n",
      "Train Loss: 0.20354242622852325\n",
      "Train Loss: 0.2035435438156128\n",
      "Train Loss: 0.20354300737380981\n",
      "Train Loss: 0.20354196429252625\n",
      "Train Loss: 0.20354090631008148\n",
      "Train Loss: 0.20354117453098297\n",
      "Train Loss: 0.20353898406028748\n",
      "Train Loss: 0.20353847742080688\n",
      "Train Loss: 0.20353661477565765\n",
      "Train Loss: 0.20353808999061584\n",
      "Train Loss: 0.20353858172893524\n",
      "Train Loss: 0.2035367786884308\n",
      "Train Loss: 0.20353174209594727\n",
      "Train Loss: 0.20353302359580994\n",
      "Train Loss: 0.20353437960147858\n",
      "Train Loss: 0.20353683829307556\n",
      "Train Loss: 0.20353470742702484\n",
      "Train Loss: 0.2035323828458786\n",
      "Train Loss: 0.20352935791015625\n",
      "Train Loss: 0.20352889597415924\n",
      "Train Loss: 0.20352701842784882\n",
      "Train Loss: 0.20352581143379211\n",
      "Train Loss: 0.2035243809223175\n",
      "Train Loss: 0.20352616906166077\n",
      "Train Loss: 0.20352572202682495\n",
      "Train Loss: 0.20352526009082794\n",
      "Train Loss: 0.20352409780025482\n",
      "Train Loss: 0.2035239338874817\n",
      "Train Loss: 0.2035224288702011\n",
      "Train Loss: 0.20352360606193542\n",
      "Train Loss: 0.2035244107246399\n",
      "Train Loss: 0.2035238891839981\n",
      "Train Loss: 0.20352119207382202\n",
      "Train Loss: 0.20352314412593842\n",
      "Train Loss: 0.20352372527122498\n",
      "Train Loss: 0.20352332293987274\n",
      "Train Loss: 0.2035209983587265\n",
      "Train Loss: 0.20352202653884888\n",
      "Train Loss: 0.20352426171302795\n",
      "Train Loss: 0.2035219967365265\n",
      "Train Loss: 0.20351915061473846\n",
      "Train Loss: 0.20352157950401306\n",
      "Train Loss: 0.2035207897424698\n",
      "Train Loss: 0.20352046191692352\n",
      "Train Loss: 0.20351840555667877\n",
      "Train Loss: 0.20351669192314148\n",
      "Train Loss: 0.20351621508598328\n",
      "Train Loss: 0.2035180926322937\n",
      "Train Loss: 0.20351800322532654\n",
      "Train Loss: 0.20351620018482208\n",
      "Train Loss: 0.20351219177246094\n",
      "Train Loss: 0.20351381599903107\n",
      "Train Loss: 0.2035171240568161\n",
      "Train Loss: 0.20351581275463104\n",
      "Train Loss: 0.2035115510225296\n",
      "Train Loss: 0.2035144716501236\n",
      "Train Loss: 0.203517884016037\n",
      "Train Loss: 0.20351536571979523\n",
      "Train Loss: 0.20351098477840424\n",
      "Train Loss: 0.20351101458072662\n",
      "Train Loss: 0.20351217687129974\n",
      "Train Loss: 0.20351485908031464\n",
      "Train Loss: 0.20351329445838928\n",
      "Train Loss: 0.20351198315620422\n",
      "Train Loss: 0.20351116359233856\n",
      "Train Loss: 0.20351147651672363\n",
      "Train Loss: 0.20351223647594452\n",
      "Train Loss: 0.20351091027259827\n",
      "Train Loss: 0.20350655913352966\n",
      "Train Loss: 0.20350654423236847\n",
      "Train Loss: 0.20350833237171173\n",
      "Train Loss: 0.20350846648216248\n",
      "Train Loss: 0.20350651443004608\n",
      "Train Loss: 0.20350617170333862\n",
      "Train Loss: 0.20350439846515656\n",
      "Train Loss: 0.203504279255867\n",
      "Train Loss: 0.20350241661071777\n",
      "Train Loss: 0.20350272953510284\n",
      "Train Loss: 0.203502357006073\n",
      "Train Loss: 0.20350445806980133\n",
      "Train Loss: 0.2035050094127655\n",
      "Train Loss: 0.20350369811058044\n",
      "Train Loss: 0.20350074768066406\n",
      "Train Loss: 0.20350277423858643\n",
      "Train Loss: 0.20350408554077148\n",
      "Train Loss: 0.2035030722618103\n",
      "Train Loss: 0.20349842309951782\n",
      "Train Loss: 0.2034982144832611\n",
      "Train Loss: 0.20349718630313873\n",
      "Train Loss: 0.20349782705307007\n",
      "Train Loss: 0.20349779725074768\n",
      "Train Loss: 0.20349764823913574\n",
      "Train Loss: 0.20349617302417755\n",
      "Train Loss: 0.20349723100662231\n",
      "Train Loss: 0.20349684357643127\n",
      "Train Loss: 0.20349708199501038\n",
      "Train Loss: 0.20349682867527008\n",
      "Train Loss: 0.20349691808223724\n",
      "Train Loss: 0.20349524915218353\n",
      "Train Loss: 0.2034958451986313\n",
      "Train Loss: 0.2034957855939865\n",
      "Train Loss: 0.20349392294883728\n",
      "Train Loss: 0.20349039137363434\n",
      "Train Loss: 0.2034919112920761\n",
      "Train Loss: 0.20349253714084625\n",
      "Train Loss: 0.20349189639091492\n",
      "Train Loss: 0.2034900039434433\n",
      "Train Loss: 0.2034897357225418\n",
      "Train Loss: 0.2034883201122284\n",
      "Train Loss: 0.20348979532718658\n",
      "Train Loss: 0.20349165797233582\n",
      "Train Loss: 0.2034895122051239\n",
      "Train Loss: 0.20348627865314484\n",
      "Train Loss: 0.20348729193210602\n",
      "Train Loss: 0.2034904658794403\n",
      "Train Loss: 0.20348922908306122\n",
      "Train Loss: 0.20348508656024933\n",
      "Train Loss: 0.20348747074604034\n",
      "Train Loss: 0.20348912477493286\n",
      "Train Loss: 0.20348791778087616\n",
      "Train Loss: 0.20348402857780457\n",
      "Train Loss: 0.2034836709499359\n",
      "Train Loss: 0.20348288118839264\n",
      "Train Loss: 0.20348413288593292\n",
      "Train Loss: 0.20348627865314484\n",
      "Train Loss: 0.20348341763019562\n",
      "Train Loss: 0.20347855985164642\n",
      "Train Loss: 0.20347841084003448\n",
      "Train Loss: 0.2034803032875061\n",
      "Train Loss: 0.20347759127616882\n",
      "Train Loss: 0.20347318053245544\n",
      "Train Loss: 0.2034750133752823\n",
      "Train Loss: 0.20347808301448822\n",
      "Train Loss: 0.2034759372472763\n",
      "Train Loss: 0.20347236096858978\n",
      "Train Loss: 0.20347487926483154\n",
      "Train Loss: 0.20347777009010315\n",
      "Train Loss: 0.2034757286310196\n",
      "Train Loss: 0.20347219705581665\n",
      "Train Loss: 0.20347365736961365\n",
      "Train Loss: 0.20347560942173004\n",
      "Train Loss: 0.20347613096237183\n",
      "Train Loss: 0.20347370207309723\n",
      "Train Loss: 0.2034752517938614\n",
      "Train Loss: 0.20347623527050018\n",
      "Train Loss: 0.20347507297992706\n",
      "Train Loss: 0.203470841050148\n",
      "Train Loss: 0.20347173511981964\n",
      "Train Loss: 0.2034754455089569\n",
      "Train Loss: 0.20347347855567932\n",
      "Train Loss: 0.203469917178154\n",
      "Train Loss: 0.2034691870212555\n",
      "Train Loss: 0.20346836745738983\n",
      "Train Loss: 0.2034686654806137\n",
      "Train Loss: 0.20346742868423462\n",
      "Train Loss: 0.20346806943416595\n",
      "Train Loss: 0.20346777141094208\n",
      "Train Loss: 0.20346839725971222\n",
      "Train Loss: 0.20346790552139282\n",
      "Train Loss: 0.2034665048122406\n",
      "Train Loss: 0.20346428453922272\n",
      "Train Loss: 0.20346520841121674\n",
      "Train Loss: 0.20346646010875702\n",
      "Train Loss: 0.20346982777118683\n",
      "Train Loss: 0.20346753299236298\n",
      "Train Loss: 0.20346865057945251\n",
      "Train Loss: 0.20347003638744354\n",
      "Train Loss: 0.20347154140472412\n",
      "Train Loss: 0.20347148180007935\n",
      "Train Loss: 0.20347118377685547\n",
      "Train Loss: 0.20346878468990326\n",
      "Train Loss: 0.20346949994564056\n",
      "Train Loss: 0.2034710943698883\n",
      "Train Loss: 0.20346935093402863\n",
      "Train Loss: 0.2034650444984436\n",
      "Train Loss: 0.20346187055110931\n",
      "Train Loss: 0.20345866680145264\n",
      "Train Loss: 0.2034606784582138\n",
      "Train Loss: 0.2034628540277481\n",
      "Train Loss: 0.20346033573150635\n",
      "Train Loss: 0.2034563571214676\n",
      "Train Loss: 0.2034539133310318\n",
      "Train Loss: 0.20345011353492737\n",
      "Train Loss: 0.2034502625465393\n",
      "Train Loss: 0.2034510374069214\n",
      "Train Loss: 0.20345339179039001\n",
      "Train Loss: 0.20345358550548553\n",
      "Train Loss: 0.20345301926136017\n",
      "Train Loss: 0.2034514844417572\n",
      "Train Loss: 0.20345203578472137\n",
      "Train Loss: 0.20345266163349152\n",
      "Train Loss: 0.203452467918396\n",
      "Train Loss: 0.2034505158662796\n",
      "Train Loss: 0.2034529745578766\n",
      "Train Loss: 0.20345373451709747\n",
      "Train Loss: 0.20345205068588257\n",
      "Train Loss: 0.20344746112823486\n",
      "Train Loss: 0.2034498155117035\n",
      "Train Loss: 0.20345373451709747\n",
      "Train Loss: 0.20345012843608856\n",
      "Train Loss: 0.20344501733779907\n",
      "Train Loss: 0.20344623923301697\n",
      "Train Loss: 0.20344851911067963\n",
      "Train Loss: 0.203447163105011\n",
      "Train Loss: 0.20344290137290955\n",
      "Train Loss: 0.20344378054141998\n",
      "Train Loss: 0.20344693958759308\n",
      "Train Loss: 0.20344547927379608\n",
      "Train Loss: 0.20344090461730957\n",
      "Train Loss: 0.20343993604183197\n",
      "Train Loss: 0.20343706011772156\n",
      "Train Loss: 0.20343881845474243\n",
      "Train Loss: 0.20344121754169464\n",
      "Train Loss: 0.203439861536026\n",
      "Train Loss: 0.20343592762947083\n",
      "Train Loss: 0.20343367755413055\n",
      "Train Loss: 0.20343010127544403\n",
      "Train Loss: 0.2034289836883545\n",
      "Train Loss: 0.20342864096164703\n",
      "Train Loss: 0.20343251526355743\n",
      "Train Loss: 0.20343425869941711\n",
      "Train Loss: 0.20343241095542908\n",
      "Train Loss: 0.20342819392681122\n",
      "Train Loss: 0.2034282684326172\n",
      "Train Loss: 0.20342934131622314\n",
      "Train Loss: 0.20343171060085297\n",
      "Train Loss: 0.2034292072057724\n",
      "Train Loss: 0.20343174040317535\n",
      "Train Loss: 0.20343108475208282\n",
      "Train Loss: 0.20343178510665894\n",
      "Train Loss: 0.20343057811260223\n",
      "Train Loss: 0.20343106985092163\n",
      "Train Loss: 0.20343150198459625\n",
      "Train Loss: 0.20343126356601715\n",
      "Train Loss: 0.20342959463596344\n",
      "Train Loss: 0.20343124866485596\n",
      "Train Loss: 0.20343178510665894\n",
      "Train Loss: 0.20343193411827087\n",
      "Train Loss: 0.20343057811260223\n",
      "Train Loss: 0.2034321278333664\n",
      "Train Loss: 0.20343364775180817\n",
      "Train Loss: 0.20343437790870667\n",
      "Train Loss: 0.2034342736005783\n",
      "Train Loss: 0.2034357637166977\n",
      "Train Loss: 0.20343555510044098\n",
      "Train Loss: 0.20343738794326782\n",
      "Train Loss: 0.2034377157688141\n",
      "Train Loss: 0.20343610644340515\n",
      "Train Loss: 0.2034323811531067\n",
      "Train Loss: 0.20343561470508575\n",
      "Train Loss: 0.20343948900699615\n",
      "Train Loss: 0.2034374177455902\n",
      "Train Loss: 0.2034342885017395\n",
      "Train Loss: 0.2034343034029007\n",
      "Train Loss: 0.20343458652496338\n",
      "Train Loss: 0.20343457162380219\n",
      "Train Loss: 0.20343297719955444\n",
      "Train Loss: 0.20343218743801117\n",
      "Train Loss: 0.20343060791492462\n",
      "Train Loss: 0.2034311592578888\n",
      "Train Loss: 0.20343229174613953\n",
      "Train Loss: 0.20343507826328278\n",
      "Train Loss: 0.2034330666065216\n",
      "Train Loss: 0.2034331113100052\n",
      "Train Loss: 0.2034320831298828\n",
      "Train Loss: 0.20343241095542908\n",
      "Train Loss: 0.20343232154846191\n",
      "Train Loss: 0.203433558344841\n",
      "Train Loss: 0.20343318581581116\n",
      "Train Loss: 0.2034340649843216\n",
      "Train Loss: 0.20343419909477234\n",
      "Train Loss: 0.20343254506587982\n",
      "Train Loss: 0.20342831313610077\n",
      "Train Loss: 0.20343004167079926\n",
      "Train Loss: 0.2034328728914261\n",
      "Train Loss: 0.20343108475208282\n",
      "Train Loss: 0.20342732965946198\n",
      "Train Loss: 0.20342637598514557\n",
      "Train Loss: 0.2034250944852829\n",
      "Train Loss: 0.2034265547990799\n",
      "Train Loss: 0.20342646539211273\n",
      "Train Loss: 0.20342464745044708\n",
      "Train Loss: 0.20342117547988892\n",
      "Train Loss: 0.2034229338169098\n",
      "Train Loss: 0.2034253180027008\n",
      "Train Loss: 0.20342352986335754\n",
      "Train Loss: 0.2034192532300949\n",
      "Train Loss: 0.20342083275318146\n",
      "Train Loss: 0.20342384278774261\n",
      "Train Loss: 0.20342206954956055\n",
      "Train Loss: 0.20341834425926208\n",
      "Train Loss: 0.20341774821281433\n",
      "Train Loss: 0.20341700315475464\n",
      "Train Loss: 0.20341840386390686\n",
      "Train Loss: 0.2034180909395218\n",
      "Train Loss: 0.20341819524765015\n",
      "Train Loss: 0.20341701805591583\n",
      "Train Loss: 0.20341692864894867\n",
      "Train Loss: 0.20341648161411285\n",
      "Train Loss: 0.20341694355010986\n",
      "Train Loss: 0.20341695845127106\n",
      "Train Loss: 0.20341771841049194\n",
      "Train Loss: 0.20341908931732178\n",
      "Train Loss: 0.20341701805591583\n",
      "Train Loss: 0.2034127563238144\n",
      "Train Loss: 0.20341402292251587\n",
      "Train Loss: 0.203417107462883\n",
      "Train Loss: 0.203415647149086\n",
      "Train Loss: 0.20341196656227112\n",
      "Train Loss: 0.20341216027736664\n",
      "Train Loss: 0.2034139186143875\n",
      "Train Loss: 0.20341432094573975\n",
      "Train Loss: 0.20341408252716064\n",
      "Train Loss: 0.2034156769514084\n",
      "Train Loss: 0.20341560244560242\n",
      "Train Loss: 0.20341572165489197\n",
      "Train Loss: 0.20341426134109497\n",
      "Train Loss: 0.20341256260871887\n",
      "Train Loss: 0.20341193675994873\n",
      "Train Loss: 0.20341387391090393\n",
      "Train Loss: 0.2034139484167099\n",
      "Train Loss: 0.20341385900974274\n",
      "Train Loss: 0.20341281592845917\n",
      "Train Loss: 0.2034146934747696\n",
      "Train Loss: 0.20341508090496063\n",
      "Train Loss: 0.2034132331609726\n",
      "Train Loss: 0.2034090757369995\n",
      "Train Loss: 0.20341093838214874\n",
      "Train Loss: 0.2034134417772293\n",
      "Train Loss: 0.20341026782989502\n",
      "Train Loss: 0.2034059762954712\n",
      "Train Loss: 0.2034067064523697\n",
      "Train Loss: 0.2034100443124771\n",
      "Train Loss: 0.2034074366092682\n",
      "Train Loss: 0.20340317487716675\n",
      "Train Loss: 0.20340225100517273\n",
      "Train Loss: 0.20340247452259064\n",
      "Train Loss: 0.2034047394990921\n",
      "Train Loss: 0.2034038007259369\n",
      "Train Loss: 0.20340339839458466\n",
      "Train Loss: 0.20340219140052795\n",
      "Train Loss: 0.20340268313884735\n",
      "Train Loss: 0.20340265333652496\n",
      "Train Loss: 0.20340339839458466\n",
      "Train Loss: 0.20340308547019958\n",
      "Train Loss: 0.2034035474061966\n",
      "Train Loss: 0.20340237021446228\n",
      "Train Loss: 0.20340242981910706\n",
      "Train Loss: 0.20340116322040558\n",
      "Train Loss: 0.20340147614479065\n",
      "Train Loss: 0.20340144634246826\n",
      "Train Loss: 0.20340178906917572\n",
      "Train Loss: 0.20340047776699066\n",
      "Train Loss: 0.20340131223201752\n",
      "Train Loss: 0.20340213179588318\n",
      "Train Loss: 0.2034008502960205\n",
      "Train Loss: 0.20339709520339966\n",
      "Train Loss: 0.20339877903461456\n",
      "Train Loss: 0.20340147614479065\n",
      "Train Loss: 0.20339958369731903\n",
      "Train Loss: 0.20339621603488922\n",
      "Train Loss: 0.2033970057964325\n",
      "Train Loss: 0.2034003585577011\n",
      "Train Loss: 0.20339825749397278\n",
      "Train Loss: 0.20339426398277283\n",
      "Train Loss: 0.20339448750019073\n",
      "Train Loss: 0.20339614152908325\n",
      "Train Loss: 0.20339666306972504\n",
      "Train Loss: 0.20339563488960266\n",
      "Train Loss: 0.2033969759941101\n",
      "Train Loss: 0.2033984214067459\n",
      "Train Loss: 0.20339655876159668\n",
      "Train Loss: 0.2033933699131012\n",
      "Train Loss: 0.20339320600032806\n",
      "Train Loss: 0.2033938765525818\n",
      "Train Loss: 0.20339378714561462\n",
      "Train Loss: 0.20339161157608032\n",
      "Train Loss: 0.20339231193065643\n",
      "Train Loss: 0.20339538156986237\n",
      "Train Loss: 0.2033938765525818\n",
      "Train Loss: 0.20339015126228333\n",
      "Train Loss: 0.20339010655879974\n",
      "Train Loss: 0.20339106023311615\n",
      "Train Loss: 0.20339339971542358\n",
      "Train Loss: 0.20339228212833405\n",
      "Train Loss: 0.20339098572731018\n",
      "Train Loss: 0.20339025557041168\n",
      "Train Loss: 0.2033897042274475\n",
      "Train Loss: 0.20338772237300873\n",
      "Train Loss: 0.20338980853557587\n",
      "Train Loss: 0.20339059829711914\n",
      "Train Loss: 0.20338863134384155\n",
      "Train Loss: 0.203385591506958\n",
      "Train Loss: 0.20338666439056396\n",
      "Train Loss: 0.20338967442512512\n",
      "Train Loss: 0.20338839292526245\n",
      "Train Loss: 0.2033846378326416\n",
      "Train Loss: 0.20338574051856995\n",
      "Train Loss: 0.20338857173919678\n",
      "Train Loss: 0.20338724553585052\n",
      "Train Loss: 0.2033831626176834\n",
      "Train Loss: 0.20338334143161774\n",
      "Train Loss: 0.2033849060535431\n",
      "Train Loss: 0.20338322222232819\n",
      "Train Loss: 0.20338019728660583\n",
      "Train Loss: 0.2033797949552536\n",
      "Train Loss: 0.2033805251121521\n",
      "Train Loss: 0.20338338613510132\n",
      "Train Loss: 0.2033820003271103\n",
      "Train Loss: 0.2033805549144745\n",
      "Train Loss: 0.20337852835655212\n",
      "Train Loss: 0.20337872207164764\n",
      "Train Loss: 0.20337821543216705\n",
      "Train Loss: 0.2033786028623581\n",
      "Train Loss: 0.20337867736816406\n",
      "Train Loss: 0.2033783346414566\n",
      "Train Loss: 0.20337820053100586\n",
      "Train Loss: 0.20337697863578796\n",
      "Train Loss: 0.20337344706058502\n",
      "Train Loss: 0.2033749520778656\n",
      "Train Loss: 0.203379288315773\n",
      "Train Loss: 0.20337702333927155\n",
      "Train Loss: 0.2033727914094925\n",
      "Train Loss: 0.20337288081645966\n",
      "Train Loss: 0.20337657630443573\n",
      "Train Loss: 0.20337441563606262\n",
      "Train Loss: 0.2033700793981552\n",
      "Train Loss: 0.20337051153182983\n",
      "Train Loss: 0.20337462425231934\n",
      "Train Loss: 0.20338499546051025\n",
      "Train Loss: 0.20338834822177887\n",
      "Train Loss: 0.20338812470436096\n",
      "Train Loss: 0.20339004695415497\n",
      "Train Loss: 0.20338888466358185\n",
      "Train Loss: 0.203388050198555\n",
      "Train Loss: 0.20338673889636993\n",
      "Train Loss: 0.20338691771030426\n",
      "Train Loss: 0.20338502526283264\n",
      "Train Loss: 0.20338425040245056\n",
      "Train Loss: 0.20338283479213715\n",
      "Train Loss: 0.203383669257164\n",
      "Train Loss: 0.20338304340839386\n",
      "Train Loss: 0.20338332653045654\n",
      "Train Loss: 0.20338483154773712\n",
      "Train Loss: 0.20338332653045654\n",
      "Train Loss: 0.20337961614131927\n",
      "Train Loss: 0.20338092744350433\n",
      "Train Loss: 0.20338289439678192\n",
      "Train Loss: 0.20338040590286255\n",
      "Train Loss: 0.20337720215320587\n",
      "Train Loss: 0.2033785879611969\n",
      "Train Loss: 0.20338135957717896\n",
      "Train Loss: 0.2033800631761551\n",
      "Train Loss: 0.20337635278701782\n",
      "Train Loss: 0.20337587594985962\n",
      "Train Loss: 0.20337584614753723\n",
      "Train Loss: 0.20337635278701782\n",
      "Train Loss: 0.20337578654289246\n",
      "Train Loss: 0.2033775895833969\n",
      "Train Loss: 0.2033776342868805\n",
      "Train Loss: 0.20337779819965363\n",
      "Train Loss: 0.20337523519992828\n",
      "Train Loss: 0.20337650179862976\n",
      "Train Loss: 0.20337837934494019\n",
      "Train Loss: 0.20337696373462677\n",
      "Train Loss: 0.20337310433387756\n",
      "Train Loss: 0.20337259769439697\n",
      "Train Loss: 0.20337264239788055\n",
      "Train Loss: 0.20337443053722382\n",
      "Train Loss: 0.20337456464767456\n",
      "Train Loss: 0.20337410271167755\n",
      "Train Loss: 0.20337270200252533\n",
      "Train Loss: 0.2033725082874298\n",
      "Train Loss: 0.20337116718292236\n",
      "Train Loss: 0.20337152481079102\n",
      "Train Loss: 0.20337152481079102\n",
      "Train Loss: 0.20337146520614624\n",
      "Train Loss: 0.2033683955669403\n",
      "Train Loss: 0.20336750149726868\n",
      "Train Loss: 0.20336800813674927\n",
      "Train Loss: 0.20336756110191345\n",
      "Train Loss: 0.203364759683609\n",
      "Train Loss: 0.2033645659685135\n",
      "Train Loss: 0.2033645510673523\n",
      "Train Loss: 0.2033640742301941\n",
      "Train Loss: 0.2033633589744568\n",
      "Train Loss: 0.20336519181728363\n",
      "Train Loss: 0.20336472988128662\n",
      "Train Loss: 0.20336385071277618\n",
      "Train Loss: 0.2033633440732956\n",
      "Train Loss: 0.2033650130033493\n",
      "Train Loss: 0.20336483418941498\n",
      "Train Loss: 0.20336508750915527\n",
      "Train Loss: 0.20336371660232544\n",
      "Train Loss: 0.20336225628852844\n",
      "Train Loss: 0.2033626139163971\n",
      "Train Loss: 0.20336271822452545\n",
      "Train Loss: 0.20336157083511353\n",
      "Train Loss: 0.20336215198040009\n",
      "Train Loss: 0.20336197316646576\n",
      "Train Loss: 0.20336292684078217\n",
      "Train Loss: 0.20336277782917023\n",
      "Train Loss: 0.20336410403251648\n",
      "Train Loss: 0.2033640742301941\n",
      "Train Loss: 0.203363835811615\n",
      "Train Loss: 0.20336201786994934\n",
      "Train Loss: 0.203362837433815\n",
      "Train Loss: 0.20336367189884186\n",
      "Train Loss: 0.2033621370792389\n",
      "Train Loss: 0.2033587247133255\n",
      "Train Loss: 0.203360915184021\n",
      "Train Loss: 0.20336367189884186\n",
      "Train Loss: 0.20336176455020905\n",
      "Train Loss: 0.2033592313528061\n",
      "Train Loss: 0.20335987210273743\n",
      "Train Loss: 0.20336247980594635\n",
      "Train Loss: 0.20336100459098816\n",
      "Train Loss: 0.20335796475410461\n",
      "Train Loss: 0.2033567577600479\n",
      "Train Loss: 0.20335669815540314\n",
      "Train Loss: 0.20335732400417328\n",
      "Train Loss: 0.20335596799850464\n",
      "Train Loss: 0.20335644483566284\n",
      "Train Loss: 0.20335432887077332\n",
      "Train Loss: 0.20335648953914642\n",
      "Train Loss: 0.2033558189868927\n",
      "Train Loss: 0.20335513353347778\n",
      "Train Loss: 0.20335321128368378\n",
      "Train Loss: 0.20335450768470764\n",
      "Train Loss: 0.20335587859153748\n",
      "Train Loss: 0.2033543437719345\n",
      "Train Loss: 0.20335231721401215\n",
      "Train Loss: 0.20335416495800018\n",
      "Train Loss: 0.2033548206090927\n",
      "Train Loss: 0.20335322618484497\n",
      "Train Loss: 0.20335082709789276\n",
      "Train Loss: 0.20335038006305695\n",
      "Train Loss: 0.20335035026073456\n",
      "Train Loss: 0.20334941148757935\n",
      "Train Loss: 0.20334841310977936\n",
      "Train Loss: 0.20334914326667786\n",
      "Train Loss: 0.2033502757549286\n",
      "Train Loss: 0.20335008203983307\n",
      "Train Loss: 0.20334665477275848\n",
      "Train Loss: 0.20334793627262115\n",
      "Train Loss: 0.20335054397583008\n",
      "Train Loss: 0.20334945619106293\n",
      "Train Loss: 0.20334629714488983\n",
      "Train Loss: 0.20334720611572266\n",
      "Train Loss: 0.20334887504577637\n",
      "Train Loss: 0.2033487856388092\n",
      "Train Loss: 0.20334741473197937\n",
      "Train Loss: 0.20334790647029877\n",
      "Train Loss: 0.20334921777248383\n",
      "Train Loss: 0.20334981381893158\n",
      "Train Loss: 0.2033495008945465\n",
      "Train Loss: 0.2033497393131256\n",
      "Train Loss: 0.2033483237028122\n",
      "Train Loss: 0.2033454030752182\n",
      "Train Loss: 0.20334143936634064\n",
      "Train Loss: 0.2033422440290451\n",
      "Train Loss: 0.20334464311599731\n",
      "Train Loss: 0.20334316790103912\n",
      "Train Loss: 0.20333944261074066\n",
      "Train Loss: 0.2033400535583496\n",
      "Train Loss: 0.20334215462207794\n",
      "Train Loss: 0.20334386825561523\n",
      "Train Loss: 0.2033437341451645\n",
      "Train Loss: 0.2033439725637436\n",
      "Train Loss: 0.20334260165691376\n",
      "Train Loss: 0.20334288477897644\n",
      "Train Loss: 0.2033412605524063\n",
      "Train Loss: 0.2033414989709854\n",
      "Train Loss: 0.20334038138389587\n",
      "Train Loss: 0.2033395767211914\n",
      "Train Loss: 0.20333853363990784\n",
      "Train Loss: 0.20333856344223022\n",
      "Train Loss: 0.2033383846282959\n",
      "Train Loss: 0.20333828032016754\n",
      "Train Loss: 0.20333707332611084\n",
      "Train Loss: 0.20333820581436157\n",
      "Train Loss: 0.20333819091320038\n",
      "Train Loss: 0.2033371925354004\n",
      "Train Loss: 0.20333664119243622\n",
      "Train Loss: 0.20333704352378845\n",
      "Train Loss: 0.20333829522132874\n",
      "Train Loss: 0.2033403366804123\n",
      "Train Loss: 0.20333833992481232\n",
      "Train Loss: 0.2033388316631317\n",
      "Train Loss: 0.2033407986164093\n",
      "Train Loss: 0.20333945751190186\n",
      "Train Loss: 0.2033359259366989\n",
      "Train Loss: 0.2033344954252243\n",
      "Train Loss: 0.20333148539066315\n",
      "Train Loss: 0.20333287119865417\n",
      "Train Loss: 0.20333576202392578\n",
      "Train Loss: 0.20333564281463623\n",
      "Train Loss: 0.20333433151245117\n",
      "Train Loss: 0.20333530008792877\n",
      "Train Loss: 0.20333662629127502\n",
      "Train Loss: 0.20333418250083923\n",
      "Train Loss: 0.2033308893442154\n",
      "Train Loss: 0.20333099365234375\n",
      "Train Loss: 0.20333091914653778\n",
      "Train Loss: 0.20333074033260345\n",
      "Train Loss: 0.2033289223909378\n",
      "Train Loss: 0.2033301591873169\n",
      "Train Loss: 0.20333033800125122\n",
      "Train Loss: 0.2033291608095169\n",
      "Train Loss: 0.2033258080482483\n",
      "Train Loss: 0.20332539081573486\n",
      "Train Loss: 0.20332293212413788\n",
      "Train Loss: 0.203324556350708\n",
      "Train Loss: 0.20332635939121246\n",
      "Train Loss: 0.20332534611225128\n",
      "Train Loss: 0.2033236026763916\n",
      "Train Loss: 0.20332500338554382\n",
      "Train Loss: 0.2033262848854065\n",
      "Train Loss: 0.2033252716064453\n",
      "Train Loss: 0.20332209765911102\n",
      "Train Loss: 0.2033221423625946\n",
      "Train Loss: 0.2033231258392334\n",
      "Train Loss: 0.20332534611225128\n",
      "Train Loss: 0.20332427322864532\n",
      "Train Loss: 0.20332440733909607\n",
      "Train Loss: 0.20332351326942444\n",
      "Train Loss: 0.20332443714141846\n",
      "Train Loss: 0.20332573354244232\n",
      "Train Loss: 0.2033245861530304\n",
      "Train Loss: 0.20332077145576477\n",
      "Train Loss: 0.20332205295562744\n",
      "Train Loss: 0.20332381129264832\n",
      "Train Loss: 0.20332364737987518\n",
      "Train Loss: 0.20332032442092896\n",
      "Train Loss: 0.20332203805446625\n",
      "Train Loss: 0.20332396030426025\n",
      "Train Loss: 0.2033224105834961\n",
      "Train Loss: 0.2033195197582245\n",
      "Train Loss: 0.20331992208957672\n",
      "Train Loss: 0.2033214271068573\n",
      "Train Loss: 0.20332196354866028\n",
      "Train Loss: 0.20332187414169312\n",
      "Train Loss: 0.20332255959510803\n",
      "Train Loss: 0.2033216655254364\n",
      "Train Loss: 0.2033228725194931\n",
      "Train Loss: 0.20332267880439758\n",
      "Train Loss: 0.2033233791589737\n",
      "Train Loss: 0.20332308113574982\n",
      "Train Loss: 0.20332464575767517\n",
      "Train Loss: 0.2033250331878662\n",
      "Train Loss: 0.20332351326942444\n",
      "Train Loss: 0.2033209502696991\n",
      "Train Loss: 0.20332138240337372\n",
      "Train Loss: 0.20332090556621552\n",
      "Train Loss: 0.20332269370555878\n",
      "Train Loss: 0.20332199335098267\n",
      "Train Loss: 0.2033209651708603\n",
      "Train Loss: 0.2033194750547409\n",
      "Train Loss: 0.20332036912441254\n",
      "Train Loss: 0.20332054793834686\n",
      "Train Loss: 0.20332030951976776\n",
      "Train Loss: 0.20331844687461853\n",
      "Train Loss: 0.20331944525241852\n",
      "Train Loss: 0.20332071185112\n",
      "Train Loss: 0.2033192366361618\n",
      "Train Loss: 0.20331653952598572\n",
      "Train Loss: 0.2033165544271469\n",
      "Train Loss: 0.20331716537475586\n",
      "Train Loss: 0.2033172994852066\n",
      "Train Loss: 0.20331576466560364\n",
      "Train Loss: 0.20331497490406036\n",
      "Train Loss: 0.20331355929374695\n",
      "Train Loss: 0.20331567525863647\n",
      "Train Loss: 0.20331500470638275\n",
      "Train Loss: 0.20331524312496185\n",
      "Train Loss: 0.2033136487007141\n",
      "Train Loss: 0.20331284403800964\n",
      "Train Loss: 0.20331138372421265\n",
      "Train Loss: 0.2033122032880783\n",
      "Train Loss: 0.20331278443336487\n",
      "Train Loss: 0.2033122479915619\n",
      "Train Loss: 0.20331048965454102\n",
      "Train Loss: 0.20331160724163055\n",
      "Train Loss: 0.20331276953220367\n",
      "Train Loss: 0.20331452786922455\n",
      "Train Loss: 0.20331457257270813\n",
      "Train Loss: 0.20331326127052307\n",
      "Train Loss: 0.203311488032341\n",
      "Train Loss: 0.20331239700317383\n",
      "Train Loss: 0.20331208407878876\n",
      "Train Loss: 0.20331192016601562\n",
      "Train Loss: 0.20331086218357086\n",
      "Train Loss: 0.20331008732318878\n",
      "Train Loss: 0.20330967009067535\n",
      "Train Loss: 0.2033107429742813\n",
      "Train Loss: 0.20331060886383057\n",
      "Train Loss: 0.20331069827079773\n",
      "Train Loss: 0.20330961048603058\n",
      "Train Loss: 0.2033095806837082\n",
      "Train Loss: 0.20330838859081268\n",
      "Train Loss: 0.20330888032913208\n",
      "Train Loss: 0.2033088058233261\n",
      "Train Loss: 0.20330923795700073\n",
      "Train Loss: 0.20330725610256195\n",
      "Train Loss: 0.20330849289894104\n",
      "Train Loss: 0.20331037044525146\n",
      "Train Loss: 0.20330874621868134\n",
      "Train Loss: 0.20330534875392914\n",
      "Train Loss: 0.20330499112606049\n",
      "Train Loss: 0.2033054083585739\n",
      "Train Loss: 0.20330511033535004\n",
      "Train Loss: 0.2033049464225769\n",
      "Train Loss: 0.20330508053302765\n",
      "Train Loss: 0.20330388844013214\n",
      "Train Loss: 0.20330403745174408\n",
      "Train Loss: 0.2033023238182068\n",
      "Train Loss: 0.2033027857542038\n",
      "Train Loss: 0.20330391824245453\n",
      "Train Loss: 0.20330600440502167\n",
      "Train Loss: 0.20330466330051422\n",
      "Train Loss: 0.20330370962619781\n",
      "Train Loss: 0.2033020555973053\n",
      "Train Loss: 0.20330242812633514\n",
      "Train Loss: 0.2033022940158844\n",
      "Train Loss: 0.20330087840557098\n",
      "Train Loss: 0.2032976597547531\n",
      "Train Loss: 0.20329752564430237\n",
      "Train Loss: 0.20329783856868744\n",
      "Train Loss: 0.2032989263534546\n",
      "Train Loss: 0.20329876244068146\n",
      "Train Loss: 0.20330017805099487\n",
      "Train Loss: 0.20329971611499786\n",
      "Train Loss: 0.20330066978931427\n",
      "Train Loss: 0.20329971611499786\n",
      "Train Loss: 0.20330017805099487\n",
      "Train Loss: 0.20329943299293518\n",
      "Train Loss: 0.20329910516738892\n",
      "Train Loss: 0.20329798758029938\n",
      "Train Loss: 0.2032991647720337\n",
      "Train Loss: 0.20329974591732025\n",
      "Train Loss: 0.20329837501049042\n",
      "Train Loss: 0.2032957226037979\n",
      "Train Loss: 0.20329566299915314\n",
      "Train Loss: 0.20329585671424866\n",
      "Train Loss: 0.20329704880714417\n",
      "Train Loss: 0.20329734683036804\n",
      "Train Loss: 0.20329754054546356\n",
      "Train Loss: 0.2032964676618576\n",
      "Train Loss: 0.20329658687114716\n",
      "Train Loss: 0.20329508185386658\n",
      "Train Loss: 0.2032955139875412\n",
      "Train Loss: 0.20329447090625763\n",
      "Train Loss: 0.20329368114471436\n",
      "Train Loss: 0.2032938152551651\n",
      "Train Loss: 0.20329350233078003\n",
      "Train Loss: 0.20329192280769348\n",
      "Train Loss: 0.20329256355762482\n",
      "Train Loss: 0.2032935470342636\n",
      "Train Loss: 0.20329251885414124\n",
      "Train Loss: 0.2032892405986786\n",
      "Train Loss: 0.2032904326915741\n",
      "Train Loss: 0.20329292118549347\n",
      "Train Loss: 0.20329205691814423\n",
      "Train Loss: 0.20328854024410248\n",
      "Train Loss: 0.20328903198242188\n",
      "Train Loss: 0.20329174399375916\n",
      "Train Loss: 0.20329146087169647\n",
      "Train Loss: 0.20329029858112335\n",
      "Train Loss: 0.20329120755195618\n",
      "Train Loss: 0.20329269766807556\n",
      "Train Loss: 0.2032911330461502\n",
      "Train Loss: 0.20328815281391144\n",
      "Train Loss: 0.20328855514526367\n",
      "Train Loss: 0.20329144597053528\n",
      "Train Loss: 0.20328959822654724\n",
      "Train Loss: 0.2032860368490219\n",
      "Train Loss: 0.20328709483146667\n",
      "Train Loss: 0.20328910648822784\n",
      "Train Loss: 0.20328785479068756\n",
      "Train Loss: 0.20328445732593536\n",
      "Train Loss: 0.20328524708747864\n",
      "Train Loss: 0.20328831672668457\n",
      "Train Loss: 0.2032867819070816\n",
      "Train Loss: 0.2032833844423294\n",
      "Train Loss: 0.20328389108181\n",
      "Train Loss: 0.20328636467456818\n",
      "Train Loss: 0.20328527688980103\n",
      "Train Loss: 0.20328205823898315\n",
      "Train Loss: 0.20328402519226074\n",
      "Train Loss: 0.20328696072101593\n",
      "Train Loss: 0.2032848745584488\n",
      "Train Loss: 0.20328162610530853\n",
      "Train Loss: 0.20328301191329956\n",
      "Train Loss: 0.2032855600118637\n",
      "Train Loss: 0.20328418910503387\n",
      "Train Loss: 0.203280970454216\n",
      "Train Loss: 0.20327886939048767\n",
      "Train Loss: 0.2032756209373474\n",
      "Train Loss: 0.20327430963516235\n",
      "Train Loss: 0.20327141880989075\n",
      "Train Loss: 0.20326955616474152\n",
      "Train Loss: 0.20326752960681915\n",
      "Train Loss: 0.2032659500837326\n",
      "Train Loss: 0.2032632976770401\n",
      "Train Loss: 0.20326130092144012\n",
      "Train Loss: 0.20325788855552673\n",
      "Train Loss: 0.20325714349746704\n",
      "Train Loss: 0.20325487852096558\n",
      "Train Loss: 0.2032584398984909\n",
      "Train Loss: 0.2032625675201416\n",
      "Train Loss: 0.20326226949691772\n",
      "Train Loss: 0.20325899124145508\n",
      "Train Loss: 0.20325975120067596\n",
      "Train Loss: 0.20326055586338043\n",
      "Train Loss: 0.2032618373632431\n",
      "Train Loss: 0.20326292514801025\n",
      "Train Loss: 0.203263521194458\n",
      "Train Loss: 0.2032630443572998\n",
      "Train Loss: 0.2032654732465744\n",
      "Train Loss: 0.2032655030488968\n",
      "Train Loss: 0.20326535403728485\n",
      "Train Loss: 0.20326480269432068\n",
      "Train Loss: 0.20326553285121918\n",
      "Train Loss: 0.203265979886055\n",
      "Train Loss: 0.20326773822307587\n",
      "Train Loss: 0.20326854288578033\n",
      "Train Loss: 0.20326776802539825\n",
      "Train Loss: 0.20326469838619232\n",
      "Train Loss: 0.2032642662525177\n",
      "Train Loss: 0.2032623440027237\n",
      "Train Loss: 0.20326274633407593\n",
      "Train Loss: 0.20326507091522217\n",
      "Train Loss: 0.20326554775238037\n",
      "Train Loss: 0.20326462388038635\n",
      "Train Loss: 0.2032639980316162\n",
      "Train Loss: 0.20326285064220428\n",
      "Train Loss: 0.20326434075832367\n",
      "Train Loss: 0.20326431095600128\n",
      "Train Loss: 0.2032637596130371\n",
      "Train Loss: 0.20326374471187592\n",
      "Train Loss: 0.20326487720012665\n",
      "Train Loss: 0.20326578617095947\n",
      "Train Loss: 0.20326508581638336\n",
      "Train Loss: 0.2032623589038849\n",
      "Train Loss: 0.20326286554336548\n",
      "Train Loss: 0.2032649666070938\n",
      "Train Loss: 0.2032649666070938\n",
      "Train Loss: 0.20326386392116547\n",
      "Train Loss: 0.20326441526412964\n",
      "Train Loss: 0.20326484739780426\n",
      "Train Loss: 0.20326468348503113\n",
      "Train Loss: 0.20326371490955353\n",
      "Train Loss: 0.2032637745141983\n",
      "Train Loss: 0.20326386392116547\n",
      "Train Loss: 0.2032642960548401\n",
      "Train Loss: 0.20326341688632965\n",
      "Train Loss: 0.20326432585716248\n",
      "Train Loss: 0.20326492190361023\n",
      "Train Loss: 0.20326469838619232\n",
      "Train Loss: 0.20326299965381622\n",
      "Train Loss: 0.20326454937458038\n",
      "Train Loss: 0.20326606929302216\n",
      "Train Loss: 0.2032649964094162\n",
      "Train Loss: 0.20326176285743713\n",
      "Train Loss: 0.20326246321201324\n",
      "Train Loss: 0.20326478779315948\n",
      "Train Loss: 0.20326365530490875\n",
      "Train Loss: 0.20326030254364014\n",
      "Train Loss: 0.20326149463653564\n",
      "Train Loss: 0.20326411724090576\n",
      "Train Loss: 0.2032640278339386\n",
      "Train Loss: 0.20326204597949982\n",
      "Train Loss: 0.2032637745141983\n",
      "Train Loss: 0.2032649964094162\n",
      "Train Loss: 0.2032638043165207\n",
      "Train Loss: 0.20326107740402222\n",
      "Train Loss: 0.2032616138458252\n",
      "Train Loss: 0.20326383411884308\n",
      "Train Loss: 0.2032620757818222\n",
      "Train Loss: 0.20325890183448792\n",
      "Train Loss: 0.20325790345668793\n",
      "Train Loss: 0.20325808227062225\n",
      "Train Loss: 0.2032599002122879\n",
      "Train Loss: 0.20325927436351776\n",
      "Train Loss: 0.2032584547996521\n",
      "Train Loss: 0.2032567262649536\n",
      "Train Loss: 0.2032584249973297\n",
      "Train Loss: 0.20325984060764313\n",
      "Train Loss: 0.2032581865787506\n",
      "Train Loss: 0.20325540006160736\n",
      "Train Loss: 0.20325514674186707\n",
      "Train Loss: 0.20325586199760437\n",
      "Train Loss: 0.20325727760791779\n",
      "Train Loss: 0.20325696468353271\n",
      "Train Loss: 0.20325753092765808\n",
      "Train Loss: 0.20325756072998047\n",
      "Train Loss: 0.20325767993927002\n",
      "Train Loss: 0.20325569808483124\n",
      "Train Loss: 0.2032575011253357\n",
      "Train Loss: 0.20325681567192078\n",
      "Train Loss: 0.2032560557126999\n",
      "Train Loss: 0.2032555490732193\n",
      "Train Loss: 0.2032562792301178\n",
      "Train Loss: 0.20325595140457153\n",
      "Train Loss: 0.2032565325498581\n",
      "Train Loss: 0.2032565176486969\n",
      "Train Loss: 0.20325574278831482\n",
      "Train Loss: 0.20325259864330292\n",
      "Train Loss: 0.2032540738582611\n",
      "Train Loss: 0.20325574278831482\n",
      "Train Loss: 0.20325450599193573\n",
      "Train Loss: 0.20325130224227905\n",
      "Train Loss: 0.20325303077697754\n",
      "Train Loss: 0.20325563848018646\n",
      "Train Loss: 0.20325370132923126\n",
      "Train Loss: 0.20325018465518951\n",
      "Train Loss: 0.2032502144575119\n",
      "Train Loss: 0.2032516449689865\n",
      "Train Loss: 0.20325198769569397\n",
      "Train Loss: 0.20325098931789398\n",
      "Train Loss: 0.2032516896724701\n",
      "Train Loss: 0.2032516747713089\n",
      "Train Loss: 0.20325177907943726\n",
      "Train Loss: 0.20325087010860443\n",
      "Train Loss: 0.20325125753879547\n",
      "Train Loss: 0.2032516896724701\n",
      "Train Loss: 0.20325113832950592\n",
      "Train Loss: 0.20325084030628204\n",
      "Train Loss: 0.2032518982887268\n",
      "Train Loss: 0.2032511830329895\n",
      "Train Loss: 0.203251451253891\n",
      "Train Loss: 0.20325057208538055\n",
      "Train Loss: 0.20325103402137756\n",
      "Train Loss: 0.20325227081775665\n",
      "Train Loss: 0.2032506763935089\n",
      "Train Loss: 0.2032477855682373\n",
      "Train Loss: 0.20324720442295074\n",
      "Train Loss: 0.20324493944644928\n",
      "Train Loss: 0.20324625074863434\n",
      "Train Loss: 0.20324820280075073\n",
      "Train Loss: 0.2032463550567627\n",
      "Train Loss: 0.20324337482452393\n",
      "Train Loss: 0.2032436728477478\n",
      "Train Loss: 0.20324541628360748\n",
      "Train Loss: 0.20324525237083435\n",
      "Train Loss: 0.20324404537677765\n",
      "Train Loss: 0.2032451182603836\n",
      "Train Loss: 0.2032468169927597\n",
      "Train Loss: 0.20324628055095673\n",
      "Train Loss: 0.20324331521987915\n",
      "Train Loss: 0.2032431662082672\n",
      "Train Loss: 0.2032415270805359\n",
      "Train Loss: 0.20324097573757172\n",
      "Train Loss: 0.2032410353422165\n",
      "Train Loss: 0.2032424807548523\n",
      "Train Loss: 0.2032417356967926\n",
      "Train Loss: 0.20324216783046722\n",
      "Train Loss: 0.20324267446994781\n",
      "Train Loss: 0.20324356853961945\n",
      "Train Loss: 0.20324444770812988\n",
      "Train Loss: 0.2032444328069687\n",
      "Train Loss: 0.20324353873729706\n",
      "Train Loss: 0.20324279367923737\n",
      "Train Loss: 0.2032412439584732\n",
      "Train Loss: 0.20324240624904633\n",
      "Train Loss: 0.20324324071407318\n",
      "Train Loss: 0.20324259996414185\n",
      "Train Loss: 0.20323961973190308\n",
      "Train Loss: 0.20323991775512695\n",
      "Train Loss: 0.2032412737607956\n",
      "Train Loss: 0.20324161648750305\n",
      "Train Loss: 0.203240767121315\n",
      "Train Loss: 0.20324036478996277\n",
      "Train Loss: 0.20323938131332397\n",
      "Train Loss: 0.2032400220632553\n",
      "Train Loss: 0.20323927700519562\n",
      "Train Loss: 0.2032395303249359\n",
      "Train Loss: 0.20323914289474487\n",
      "Train Loss: 0.20323917269706726\n",
      "Train Loss: 0.20323899388313293\n",
      "Train Loss: 0.20324033498764038\n",
      "Train Loss: 0.20324070751667023\n",
      "Train Loss: 0.20323951542377472\n",
      "Train Loss: 0.20323646068572998\n",
      "Train Loss: 0.20323728024959564\n",
      "Train Loss: 0.20323911309242249\n",
      "Train Loss: 0.20323804020881653\n",
      "Train Loss: 0.20323629677295685\n",
      "Train Loss: 0.20323783159255981\n",
      "Train Loss: 0.20323801040649414\n",
      "Train Loss: 0.203237846493721\n",
      "Train Loss: 0.2032366693019867\n",
      "Train Loss: 0.20323710143566132\n",
      "Train Loss: 0.20323671400547028\n",
      "Train Loss: 0.2032366842031479\n",
      "Train Loss: 0.20323529839515686\n",
      "Train Loss: 0.20323634147644043\n",
      "Train Loss: 0.20323745906352997\n",
      "Train Loss: 0.20323744416236877\n",
      "Train Loss: 0.2032371461391449\n",
      "Train Loss: 0.20323769748210907\n",
      "Train Loss: 0.20323696732521057\n",
      "Train Loss: 0.2032373696565628\n",
      "Train Loss: 0.2032373994588852\n",
      "Train Loss: 0.2032374143600464\n",
      "Train Loss: 0.2032369077205658\n",
      "Train Loss: 0.20323649048805237\n",
      "Train Loss: 0.20323693752288818\n",
      "Train Loss: 0.2032364308834076\n",
      "Train Loss: 0.20323385298252106\n",
      "Train Loss: 0.20323382318019867\n",
      "Train Loss: 0.2032342255115509\n",
      "Train Loss: 0.2032347172498703\n",
      "Train Loss: 0.2032335251569748\n",
      "Train Loss: 0.20323362946510315\n",
      "Train Loss: 0.2032330185174942\n",
      "Train Loss: 0.20323343575000763\n",
      "Train Loss: 0.20323331654071808\n",
      "Train Loss: 0.20323358476161957\n",
      "Train Loss: 0.2032325565814972\n",
      "Train Loss: 0.2032328099012375\n",
      "Train Loss: 0.20323191583156586\n",
      "Train Loss: 0.2032325118780136\n",
      "Train Loss: 0.20323313772678375\n",
      "Train Loss: 0.2032320648431778\n",
      "Train Loss: 0.2032296359539032\n",
      "Train Loss: 0.20323055982589722\n",
      "Train Loss: 0.20323312282562256\n",
      "Train Loss: 0.20323039591312408\n",
      "Train Loss: 0.20322662591934204\n",
      "Train Loss: 0.20322589576244354\n",
      "Train Loss: 0.2032272219657898\n",
      "Train Loss: 0.20322827994823456\n",
      "Train Loss: 0.20322805643081665\n",
      "Train Loss: 0.20322811603546143\n",
      "Train Loss: 0.20322690904140472\n",
      "Train Loss: 0.2032262235879898\n",
      "Train Loss: 0.20322516560554504\n",
      "Train Loss: 0.20322619378566742\n",
      "Train Loss: 0.20322751998901367\n",
      "Train Loss: 0.20322705805301666\n",
      "Train Loss: 0.20322446525096893\n",
      "Train Loss: 0.2032254934310913\n",
      "Train Loss: 0.20322680473327637\n",
      "Train Loss: 0.20322661101818085\n",
      "Train Loss: 0.20322518050670624\n",
      "Train Loss: 0.20322635769844055\n",
      "Train Loss: 0.20322741568088531\n",
      "Train Loss: 0.20322631299495697\n",
      "Train Loss: 0.20322373509407043\n",
      "Train Loss: 0.2032247632741928\n",
      "Train Loss: 0.20322653651237488\n",
      "Train Loss: 0.2032250463962555\n",
      "Train Loss: 0.20322275161743164\n",
      "Train Loss: 0.20322367548942566\n",
      "Train Loss: 0.2032260000705719\n",
      "Train Loss: 0.20322535932064056\n",
      "Train Loss: 0.20322254300117493\n",
      "Train Loss: 0.20322200655937195\n",
      "Train Loss: 0.20322054624557495\n",
      "Train Loss: 0.20322075486183167\n",
      "Train Loss: 0.2032199501991272\n",
      "Train Loss: 0.20322149991989136\n",
      "Train Loss: 0.20322248339653015\n",
      "Train Loss: 0.20322144031524658\n",
      "Train Loss: 0.20321838557720184\n",
      "Train Loss: 0.2032182812690735\n",
      "Train Loss: 0.2032172530889511\n",
      "Train Loss: 0.20321901142597198\n",
      "Train Loss: 0.20321927964687347\n",
      "Train Loss: 0.20321917533874512\n",
      "Train Loss: 0.20321817696094513\n",
      "Train Loss: 0.2032197117805481\n",
      "Train Loss: 0.20321998000144958\n",
      "Train Loss: 0.20321965217590332\n",
      "Train Loss: 0.20321863889694214\n",
      "Train Loss: 0.2032192200422287\n",
      "Train Loss: 0.20322050154209137\n",
      "Train Loss: 0.2032199501991272\n",
      "Train Loss: 0.20321743190288544\n",
      "Train Loss: 0.2032184898853302\n",
      "Train Loss: 0.2032208889722824\n",
      "Train Loss: 0.20321887731552124\n",
      "Train Loss: 0.20321553945541382\n",
      "Train Loss: 0.20321528613567352\n",
      "Train Loss: 0.20321638882160187\n",
      "Train Loss: 0.20321814715862274\n",
      "Train Loss: 0.2032175213098526\n",
      "Train Loss: 0.20321807265281677\n",
      "Train Loss: 0.20321834087371826\n",
      "Train Loss: 0.20321781933307648\n",
      "Train Loss: 0.20321549475193024\n",
      "Train Loss: 0.20321521162986755\n",
      "Train Loss: 0.20321407914161682\n",
      "Train Loss: 0.20321603119373322\n",
      "Train Loss: 0.20321562886238098\n",
      "Train Loss: 0.20321601629257202\n",
      "Train Loss: 0.2032158523797989\n",
      "Train Loss: 0.20321513712406158\n",
      "Train Loss: 0.2032124400138855\n",
      "Train Loss: 0.20321202278137207\n",
      "Train Loss: 0.20320969820022583\n",
      "Train Loss: 0.20321092009544373\n",
      "Train Loss: 0.20321325957775116\n",
      "Train Loss: 0.20321275293827057\n",
      "Train Loss: 0.20320986211299896\n",
      "Train Loss: 0.20321153104305267\n",
      "Train Loss: 0.2032141238451004\n",
      "Train Loss: 0.20321236550807953\n",
      "Train Loss: 0.2032093107700348\n",
      "Train Loss: 0.20320962369441986\n",
      "Train Loss: 0.20321187376976013\n",
      "Train Loss: 0.20321182906627655\n",
      "Train Loss: 0.20321007072925568\n",
      "Train Loss: 0.20321111381053925\n",
      "Train Loss: 0.20321287214756012\n",
      "Train Loss: 0.2032116949558258\n",
      "Train Loss: 0.2032085806131363\n",
      "Train Loss: 0.2032078504562378\n",
      "Train Loss: 0.20320682227611542\n",
      "Train Loss: 0.20320729911327362\n",
      "Train Loss: 0.20320725440979004\n",
      "Train Loss: 0.20320694148540497\n",
      "Train Loss: 0.20320576429367065\n",
      "Train Loss: 0.20320703089237213\n",
      "Train Loss: 0.2032088339328766\n",
      "Train Loss: 0.20320729911327362\n",
      "Train Loss: 0.20320463180541992\n",
      "Train Loss: 0.20320488512516022\n",
      "Train Loss: 0.20320618152618408\n",
      "Train Loss: 0.20320509374141693\n",
      "Train Loss: 0.20320329070091248\n",
      "Train Loss: 0.20320387184619904\n",
      "Train Loss: 0.20320376753807068\n",
      "Train Loss: 0.2032042145729065\n",
      "Train Loss: 0.20320463180541992\n",
      "Train Loss: 0.20320355892181396\n",
      "Train Loss: 0.20320123434066772\n",
      "Train Loss: 0.20320254564285278\n",
      "Train Loss: 0.20320387184619904\n",
      "Train Loss: 0.20320439338684082\n",
      "Train Loss: 0.2032042294740677\n",
      "Train Loss: 0.2032041996717453\n",
      "Train Loss: 0.20320256054401398\n",
      "Train Loss: 0.2032034546136856\n",
      "Train Loss: 0.2032039910554886\n",
      "Train Loss: 0.2032049596309662\n",
      "Train Loss: 0.2032049298286438\n",
      "Train Loss: 0.20320597290992737\n",
      "Train Loss: 0.20320537686347961\n",
      "Train Loss: 0.20320552587509155\n",
      "Train Loss: 0.20320472121238708\n",
      "Train Loss: 0.2032056301832199\n",
      "Train Loss: 0.20320649445056915\n",
      "Train Loss: 0.20320583879947662\n",
      "Train Loss: 0.2032034546136856\n",
      "Train Loss: 0.20320335030555725\n",
      "Train Loss: 0.2032029628753662\n",
      "Train Loss: 0.20320376753807068\n",
      "Train Loss: 0.20320363342761993\n",
      "Train Loss: 0.20320382714271545\n",
      "Train Loss: 0.20320352911949158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.20320424437522888\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "trainer = pl.Trainer(default_root_dir=\"model/\", max_epochs=2000)\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c2e07fe5204541ade917ca34b64b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.13442549109458923\n",
      "[{}]\n"
     ]
    }
   ],
   "source": [
    "result = trainer.test(model=model, dataloaders=val_loader)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model to predict btc Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predict': array([[[37978.48024124, 37838.65525654, 37970.16131049, ...,\n",
      "         47506.57934862, 47349.00813818, 47888.68482277]],\n",
      "\n",
      "       [[34528.58326685, 34401.45973278, 34521.02001285, ...,\n",
      "         43191.1669541 , 43047.90922958, 43538.56265284]],\n",
      "\n",
      "       [[34528.58326685, 34401.45973278, 34521.02001285, ...,\n",
      "         43191.1669541 , 43047.90922958, 43538.56265284]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[34528.58326685, 34401.45973278, 34521.02001285, ...,\n",
      "         43191.1669541 , 43047.90922958, 43538.56265284]],\n",
      "\n",
      "       [[34528.58326685, 34401.45973278, 34521.02001285, ...,\n",
      "         43191.1669541 , 43047.90922958, 43538.56265284]],\n",
      "\n",
      "       [[34528.59039921, 34401.46683887, 34521.02714363, ...,\n",
      "         43191.17587582, 43047.91812171, 43538.57164633]]]), 'actual': array([[[26096.20569737, 26000.12756209, 26090.48949897, ...,\n",
      "         32643.26162567, 32534.98950174, 32905.81828903]],\n",
      "\n",
      "       [[26286.36310109, 26189.58486523, 26280.60525   , ...,\n",
      "         32881.12600917, 32772.06492969, 33145.59586611]],\n",
      "\n",
      "       [[26129.86504671, 26033.66298814, 26124.14147546, ...,\n",
      "         32685.36548396, 32576.95370872, 32948.26079756]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[34966.97324556, 34838.23569556, 34959.31396517, ...,\n",
      "         43739.54087998, 43594.4642928 , 44091.3472663 ]],\n",
      "\n",
      "       [[34503.08154443, 34376.05189979, 34495.5238764 , ...,\n",
      "         43159.26732062, 43016.11540173, 43506.40644386]],\n",
      "\n",
      "       [[34460.34806103, 34333.47574781, 34452.79975348, ...,\n",
      "         43105.81279565, 42962.8381763 , 43452.52197283]]]), 'losses': tensor(0.1344), 'date': [Timestamp('2023-08-19 00:00:00+0000', tz='UTC'), Timestamp('2023-08-20 00:00:00+0000', tz='UTC'), Timestamp('2023-08-21 00:00:00+0000', tz='UTC'), Timestamp('2023-08-22 00:00:00+0000', tz='UTC'), Timestamp('2023-08-23 00:00:00+0000', tz='UTC'), Timestamp('2023-08-24 00:00:00+0000', tz='UTC'), Timestamp('2023-08-25 00:00:00+0000', tz='UTC'), Timestamp('2023-08-26 00:00:00+0000', tz='UTC'), Timestamp('2023-08-27 00:00:00+0000', tz='UTC'), Timestamp('2023-08-28 00:00:00+0000', tz='UTC'), Timestamp('2023-08-29 00:00:00+0000', tz='UTC'), Timestamp('2023-08-30 00:00:00+0000', tz='UTC'), Timestamp('2023-08-31 00:00:00+0000', tz='UTC'), Timestamp('2023-09-01 00:00:00+0000', tz='UTC'), Timestamp('2023-09-02 00:00:00+0000', tz='UTC'), Timestamp('2023-09-03 00:00:00+0000', tz='UTC'), Timestamp('2023-09-04 00:00:00+0000', tz='UTC'), Timestamp('2023-09-05 00:00:00+0000', tz='UTC'), Timestamp('2023-09-06 00:00:00+0000', tz='UTC'), Timestamp('2023-09-07 00:00:00+0000', tz='UTC'), Timestamp('2023-09-08 00:00:00+0000', tz='UTC'), Timestamp('2023-09-09 00:00:00+0000', tz='UTC'), Timestamp('2023-09-10 00:00:00+0000', tz='UTC'), Timestamp('2023-09-11 00:00:00+0000', tz='UTC'), Timestamp('2023-09-12 00:00:00+0000', tz='UTC'), Timestamp('2023-09-13 00:00:00+0000', tz='UTC'), Timestamp('2023-09-14 00:00:00+0000', tz='UTC'), Timestamp('2023-09-15 00:00:00+0000', tz='UTC'), Timestamp('2023-09-16 00:00:00+0000', tz='UTC'), Timestamp('2023-09-17 00:00:00+0000', tz='UTC'), Timestamp('2023-09-18 00:00:00+0000', tz='UTC'), Timestamp('2023-09-19 00:00:00+0000', tz='UTC'), Timestamp('2023-09-20 00:00:00+0000', tz='UTC'), Timestamp('2023-09-21 00:00:00+0000', tz='UTC'), Timestamp('2023-09-22 00:00:00+0000', tz='UTC'), Timestamp('2023-09-23 00:00:00+0000', tz='UTC'), Timestamp('2023-09-24 00:00:00+0000', tz='UTC'), Timestamp('2023-09-25 00:00:00+0000', tz='UTC'), Timestamp('2023-09-26 00:00:00+0000', tz='UTC'), Timestamp('2023-09-27 00:00:00+0000', tz='UTC'), Timestamp('2023-09-28 00:00:00+0000', tz='UTC'), Timestamp('2023-09-29 00:00:00+0000', tz='UTC'), Timestamp('2023-09-30 00:00:00+0000', tz='UTC'), Timestamp('2023-10-01 00:00:00+0000', tz='UTC'), Timestamp('2023-10-02 00:00:00+0000', tz='UTC'), Timestamp('2023-10-03 00:00:00+0000', tz='UTC'), Timestamp('2023-10-04 00:00:00+0000', tz='UTC'), Timestamp('2023-10-05 00:00:00+0000', tz='UTC'), Timestamp('2023-10-06 00:00:00+0000', tz='UTC'), Timestamp('2023-10-07 00:00:00+0000', tz='UTC'), Timestamp('2023-10-08 00:00:00+0000', tz='UTC'), Timestamp('2023-10-09 00:00:00+0000', tz='UTC'), Timestamp('2023-10-10 00:00:00+0000', tz='UTC'), Timestamp('2023-10-11 00:00:00+0000', tz='UTC'), Timestamp('2023-10-12 00:00:00+0000', tz='UTC'), Timestamp('2023-10-13 00:00:00+0000', tz='UTC'), Timestamp('2023-10-14 00:00:00+0000', tz='UTC'), Timestamp('2023-10-15 00:00:00+0000', tz='UTC'), Timestamp('2023-10-16 00:00:00+0000', tz='UTC'), Timestamp('2023-10-17 00:00:00+0000', tz='UTC'), Timestamp('2023-10-18 00:00:00+0000', tz='UTC'), Timestamp('2023-10-19 00:00:00+0000', tz='UTC'), Timestamp('2023-10-20 00:00:00+0000', tz='UTC'), Timestamp('2023-10-21 00:00:00+0000', tz='UTC'), Timestamp('2023-10-22 00:00:00+0000', tz='UTC'), Timestamp('2023-10-23 00:00:00+0000', tz='UTC'), Timestamp('2023-10-24 00:00:00+0000', tz='UTC'), Timestamp('2023-10-25 00:00:00+0000', tz='UTC'), Timestamp('2023-10-26 00:00:00+0000', tz='UTC'), Timestamp('2023-10-27 00:00:00+0000', tz='UTC'), Timestamp('2023-10-28 00:00:00+0000', tz='UTC'), Timestamp('2023-10-29 00:00:00+0000', tz='UTC'), Timestamp('2023-10-30 00:00:00+0000', tz='UTC'), Timestamp('2023-10-31 00:00:00+0000', tz='UTC'), Timestamp('2023-11-01 00:00:00+0000', tz='UTC'), Timestamp('2023-11-02 00:00:00+0000', tz='UTC'), Timestamp('2023-11-03 00:00:00+0000', tz='UTC'), Timestamp('2023-11-04 00:00:00+0000', tz='UTC'), Timestamp('2023-11-05 00:00:00+0000', tz='UTC'), Timestamp('2023-11-06 00:00:00+0000', tz='UTC'), Timestamp('2023-11-07 00:00:00+0000', tz='UTC'), Timestamp('2023-11-08 00:00:00+0000', tz='UTC'), Timestamp('2023-11-09 00:00:00+0000', tz='UTC'), Timestamp('2023-11-10 00:00:00+0000', tz='UTC'), Timestamp('2023-11-11 00:00:00+0000', tz='UTC'), Timestamp('2023-11-12 00:00:00+0000', tz='UTC'), Timestamp('2023-11-13 00:00:00+0000', tz='UTC'), Timestamp('2023-11-14 00:00:00+0000', tz='UTC'), Timestamp('2023-11-15 00:00:00+0000', tz='UTC'), Timestamp('2023-11-16 00:00:00+0000', tz='UTC'), Timestamp('2023-11-17 00:00:00+0000', tz='UTC'), Timestamp('2023-11-18 00:00:00+0000', tz='UTC'), Timestamp('2023-11-19 00:00:00+0000', tz='UTC'), Timestamp('2023-11-20 00:00:00+0000', tz='UTC'), Timestamp('2023-11-21 00:00:00+0000', tz='UTC'), Timestamp('2023-11-22 00:00:00+0000', tz='UTC'), Timestamp('2023-11-23 00:00:00+0000', tz='UTC'), Timestamp('2023-11-24 00:00:00+0000', tz='UTC'), Timestamp('2023-11-25 00:00:00+0000', tz='UTC'), Timestamp('2023-11-26 00:00:00+0000', tz='UTC'), Timestamp('2023-11-27 00:00:00+0000', tz='UTC'), Timestamp('2023-11-28 00:00:00+0000', tz='UTC'), Timestamp('2023-11-29 00:00:00+0000', tz='UTC'), Timestamp('2023-11-30 00:00:00+0000', tz='UTC'), Timestamp('2023-12-01 00:00:00+0000', tz='UTC'), Timestamp('2023-12-02 00:00:00+0000', tz='UTC'), Timestamp('2023-12-03 00:00:00+0000', tz='UTC'), Timestamp('2023-12-04 00:00:00+0000', tz='UTC'), Timestamp('2023-12-05 00:00:00+0000', tz='UTC'), Timestamp('2023-12-06 00:00:00+0000', tz='UTC'), Timestamp('2023-12-07 00:00:00+0000', tz='UTC'), Timestamp('2023-12-08 00:00:00+0000', tz='UTC'), Timestamp('2023-12-09 00:00:00+0000', tz='UTC'), Timestamp('2023-12-10 00:00:00+0000', tz='UTC'), Timestamp('2023-12-11 00:00:00+0000', tz='UTC'), Timestamp('2023-12-12 00:00:00+0000', tz='UTC'), Timestamp('2023-12-13 00:00:00+0000', tz='UTC'), Timestamp('2023-12-14 00:00:00+0000', tz='UTC'), Timestamp('2023-12-15 00:00:00+0000', tz='UTC'), Timestamp('2023-12-16 00:00:00+0000', tz='UTC'), Timestamp('2023-12-17 00:00:00+0000', tz='UTC'), Timestamp('2023-12-18 00:00:00+0000', tz='UTC'), Timestamp('2023-12-19 00:00:00+0000', tz='UTC'), Timestamp('2023-12-20 00:00:00+0000', tz='UTC'), Timestamp('2023-12-21 00:00:00+0000', tz='UTC'), Timestamp('2023-12-22 00:00:00+0000', tz='UTC'), Timestamp('2023-12-23 00:00:00+0000', tz='UTC'), Timestamp('2023-12-24 00:00:00+0000', tz='UTC'), Timestamp('2023-12-26 00:00:00+0000', tz='UTC')]}\n"
     ]
    }
   ],
   "source": [
    "x = val_loader.dataset.X\n",
    "y = val_loader.dataset.y\n",
    "ref = val_loader.dataset.initial_price\n",
    "date = val_loader.dataset.current_date\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_hat = model(x)\n",
    "    \n",
    "print({\n",
    "    'predict':ref*(1+np.array(y_hat)), \n",
    "    'actual':ref*(1+np.array(y)), \n",
    "    'losses':nn.L1Loss()(y, y_hat),\n",
    "    'date':date,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_out = np.multiply( (np.array(y_hat)+1).flatten(), ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "close": [
          29792.015625,
          29908.744140625,
          29771.802734375,
          30084.5390625,
          29176.916015625,
          29227.390625,
          29354.97265625,
          29210.689453125,
          29319.24609375,
          29356.91796875,
          29275.30859375,
          29230.111328125,
          29675.732421875,
          29151.958984375,
          29178.6796875,
          29074.091796875,
          29042.126953125,
          29041.85546875,
          29180.578125,
          29765.4921875,
          29561.494140625,
          29429.591796875,
          29397.71484375,
          29415.96484375,
          29282.9140625,
          29408.443359375,
          29170.34765625,
          28701.779296875,
          26664.55078125,
          26049.556640625,
          26096.205078125,
          26189.583984375,
          26124.140625,
          26031.65625,
          26431.640625,
          26162.373046875,
          26047.66796875,
          26008.462890625,
          26089.693359375,
          26106.150390625,
          27727.392578125,
          27297.265625,
          25931.47265625,
          25800.724609375,
          25868.798828125,
          25969.56640625,
          25812.416015625,
          25779.982421875,
          25753.236328125,
          26240.1953125,
          25905.654296875,
          25895.677734375,
          25832.2265625,
          25162.654296875,
          25833.34375,
          26228.32421875,
          26539.673828125,
          26608.693359375,
          26568.28125,
          26534.1875,
          26754.28125,
          27211.1171875,
          27132.0078125,
          26567.6328125,
          26579.568359375,
          26579.390625,
          26256.826171875,
          26298.48046875,
          26217.25,
          26352.716796875,
          27021.546875,
          26911.720703125,
          26967.916015625,
          27983.75,
          27530.78515625,
          27429.978515625,
          27799.39453125,
          27415.912109375,
          27946.59765625,
          27968.83984375,
          27935.08984375,
          27583.677734375,
          27391.01953125,
          26873.3203125,
          26756.798828125,
          26862.375,
          26861.70703125,
          27159.65234375,
          28519.466796875,
          28415.748046875,
          28328.341796875,
          28719.806640625,
          29682.94921875,
          29918.412109375,
          29993.896484375,
          33086.234375,
          33901.52734375,
          34502.8203125,
          34156.6484375,
          33909.80078125,
          34089.57421875,
          34538.48046875,
          34502.36328125,
          34667.78125,
          35437.25390625,
          34938.2421875,
          34732.32421875,
          35082.1953125,
          35049.35546875,
          35037.37109375,
          35443.5625,
          35655.27734375,
          36693.125,
          37313.96875,
          37138.05078125,
          37054.51953125,
          36502.35546875,
          35537.640625,
          37880.58203125,
          36154.76953125,
          36596.68359375,
          36585.703125,
          37386.546875,
          37476.95703125,
          35813.8125,
          37432.33984375,
          37289.62109375,
          37720.28125,
          37796.79296875,
          37479.12109375,
          37254.16796875,
          37831.0859375,
          37858.4921875,
          37712.74609375,
          38688.75,
          39476.33203125,
          39978.390625,
          41980.09765625,
          44080.6484375,
          43746.4453125,
          43292.6640625,
          44166.6015625,
          43725.984375,
          43779.69921875,
          41243.83203125,
          41450.22265625,
          42890.7421875,
          43023.97265625,
          41929.7578125,
          42240.1171875,
          41364.6640625,
          42623.5390625,
          42270.52734375,
          43652.25,
          43869.15234375,
          43997.90234375,
          43739.54296875,
          43016.1171875,
          43452.5234375
         ],
         "high": [
          30195.53125,
          30045.998046875,
          29991.615234375,
          30330.640625,
          30093.39453125,
          29353.16015625,
          29675.552734375,
          29560.966796875,
          29521.513671875,
          29396.84375,
          29443.169921875,
          29489.873046875,
          29675.732421875,
          29987.998046875,
          29375.70703125,
          29302.078125,
          29102.46484375,
          29160.822265625,
          29244.28125,
          30176.796875,
          30093.435546875,
          29688.564453125,
          29517.7734375,
          29465.11328125,
          29441.43359375,
          29660.25390625,
          29439.12109375,
          29221.9765625,
          28745.947265625,
          26808.1953125,
          26249.44921875,
          26260.681640625,
          26220.201171875,
          26135.5078125,
          26786.8984375,
          26554.91015625,
          26248.103515625,
          26107.384765625,
          26165.373046875,
          26198.578125,
          28089.337890625,
          27760.16015625,
          27456.078125,
          26125.869140625,
          25970.28515625,
          26087.1484375,
          26081.525390625,
          25858.375,
          25953.015625,
          26409.302734375,
          26414.005859375,
          25921.9765625,
          25978.130859375,
          25883.947265625,
          26451.939453125,
          26376.11328125,
          26774.623046875,
          26840.498046875,
          26754.76953125,
          26617.998046875,
          27414.734375,
          27488.763671875,
          27379.505859375,
          27152.939453125,
          26726.078125,
          26634.185546875,
          26716.05859375,
          26421.5078125,
          26389.884765625,
          26817.841796875,
          27259.5,
          27225.9375,
          27091.794921875,
          28047.23828125,
          28494.458984375,
          27667.19140625,
          27826.658203125,
          28091.861328125,
          28252.537109375,
          28028.091796875,
          28102.169921875,
          27989.470703125,
          27715.84765625,
          27474.115234375,
          26921.439453125,
          27092.697265625,
          26969,
          27289.169921875,
          29448.138671875,
          28618.751953125,
          28889.009765625,
          28892.474609375,
          30104.0859375,
          30287.482421875,
          30199.43359375,
          34370.4375,
          35150.43359375,
          35133.7578125,
          34832.91015625,
          34238.2109375,
          34399.390625,
          34743.26171875,
          34843.93359375,
          34719.25390625,
          35527.9296875,
          35919.84375,
          34942.47265625,
          35256.03125,
          35340.33984375,
          35286.02734375,
          35892.41796875,
          35994.41796875,
          37926.2578125,
          37493.80078125,
          37407.09375,
          37227.69140625,
          37405.1171875,
          36753.3515625,
          37964.89453125,
          37934.625,
          36704.484375,
          36839.28125,
          37509.35546875,
          37756.8203125,
          37631.140625,
          37856.98046875,
          37643.91796875,
          38415.33984375,
          37892.4296875,
          37820.30078125,
          37559.35546875,
          38368.48046875,
          38366.11328125,
          38141.75390625,
          38954.109375,
          39678.9375,
          40135.60546875,
          42371.75,
          44408.6640625,
          44265.76953125,
          44042.58984375,
          44705.515625,
          44361.2578125,
          44034.625,
          43808.375,
          42048.3046875,
          43429.78125,
          43390.859375,
          43087.82421875,
          42664.9453125,
          42359.49609375,
          42720.296875,
          43354.296875,
          44275.5859375,
          44240.66796875,
          44367.95703125,
          44015.69921875,
          43945.5234375,
          43599.84765625
         ],
         "low": [
          29638.095703125,
          29733.8515625,
          29664.12109375,
          29741.52734375,
          28934.294921875,
          29062.43359375,
          29113.912109375,
          29099.3515625,
          29125.845703125,
          29264.166015625,
          29059.501953125,
          29131.578125,
          28657.0234375,
          28946.509765625,
          28959.48828125,
          28885.3359375,
          28957.796875,
          28963.833984375,
          28724.140625,
          29113.814453125,
          29376.80078125,
          29354.447265625,
          29253.517578125,
          29357.587890625,
          29265.806640625,
          29124.10546875,
          29088.853515625,
          28701.779296875,
          25409.111328125,
          25668.921875,
          25802.408203125,
          26004.314453125,
          25846.087890625,
          25520.728515625,
          25804.998046875,
          25914.92578125,
          25786.8125,
          25983.87890625,
          25965.09765625,
          25880.599609375,
          25912.62890625,
          27069.20703125,
          25752.9296875,
          25362.609375,
          25753.09375,
          25817.03125,
          25657.025390625,
          25589.98828125,
          25404.359375,
          25608.201171875,
          25677.48046875,
          25810.494140625,
          25640.26171875,
          24930.296875,
          25133.078125,
          25781.123046875,
          26171.451171875,
          26240.701171875,
          26473.890625,
          26445.07421875,
          26415.515625,
          26681.60546875,
          26864.08203125,
          26389.30078125,
          26495.533203125,
          26520.51953125,
          26221.05078125,
          26011.46875,
          26090.712890625,
          26111.46484375,
          26327.322265625,
          26721.763671875,
          26888.96875,
          26965.09375,
          27347.787109375,
          27216.001953125,
          27248.10546875,
          27375.6015625,
          27215.552734375,
          27870.423828125,
          27740.662109375,
          27302.5625,
          27301.654296875,
          26561.099609375,
          26558.3203125,
          26686.322265625,
          26814.5859375,
          26817.89453125,
          27130.47265625,
          28110.185546875,
          28174.251953125,
          28177.98828125,
          28601.669921875,
          29481.751953125,
          29720.3125,
          30097.828125,
          32880.76171875,
          33709.109375,
          33762.32421875,
          33416.88671875,
          33874.8046875,
          33947.56640625,
          34110.97265625,
          34083.30859375,
          34170.69140625,
          34401.57421875,
          34133.44140625,
          34616.69140625,
          34594.2421875,
          34765.36328125,
          34545.81640625,
          35147.80078125,
          35592.1015625,
          36362.75390625,
          36773.66796875,
          36779.1171875,
          36399.60546875,
          34948.5,
          35383.78125,
          35545.47265625,
          35901.234375,
          36233.3125,
          36414.59765625,
          36882.53125,
          35813.8125,
          35670.97265625,
          36923.86328125,
          37261.60546875,
          37617.41796875,
          37162.75,
          36750.12890625,
          36891.08984375,
          37612.6328125,
          37531.140625,
          37629.359375,
          38652.59375,
          39298.1640625,
          39978.62890625,
          41421.1484375,
          43478.08203125,
          42880.6484375,
          43125.296875,
          43627.59765625,
          43593.28515625,
          40234.578125,
          40667.5625,
          40676.8671875,
          41767.08984375,
          41692.96875,
          41723.11328125,
          41274.54296875,
          40530.2578125,
          41826.3359375,
          42223.81640625,
          43330.05078125,
          43441.96875,
          43351.35546875,
          42786.91796875,
          43413.09375
         ],
         "name": "Actual Price",
         "open": [
          29915.25,
          29805.111328125,
          29908.697265625,
          29790.111328125,
          30081.662109375,
          29178.970703125,
          29225.759765625,
          29353.798828125,
          29212.1640625,
          29319.4453125,
          29357.09375,
          29278.314453125,
          29230.873046875,
          29704.146484375,
          29161.8125,
          29174.3828125,
          29075.388671875,
          29043.701171875,
          29038.513671875,
          29180.01953125,
          29766.6953125,
          29563.97265625,
          29424.90234375,
          29399.787109375,
          29416.59375,
          29283.263671875,
          29408.048828125,
          29169.07421875,
          28699.802734375,
          26636.078125,
          26047.83203125,
          26096.861328125,
          26188.69140625,
          26130.748046875,
          26040.474609375,
          26431.51953125,
          26163.6796875,
          26047.234375,
          26008.2421875,
          26089.615234375,
          26102.486328125,
          27726.083984375,
          27301.9296875,
          25934.021484375,
          25800.91015625,
          25869.47265625,
          25968.169921875,
          25814.95703125,
          25783.931640625,
          25748.3125,
          26245.208984375,
          25905.42578125,
          25895.2109375,
          25831.71484375,
          25160.658203125,
          25837.5546875,
          26228.27734375,
          26533.818359375,
          26606.19921875,
          26567.927734375,
          26532.994140625,
          26760.8515625,
          27210.228515625,
          27129.83984375,
          26564.056640625,
          26578.556640625,
          26579.373046875,
          26253.775390625,
          26294.7578125,
          26209.498046875,
          26355.8125,
          27024.841796875,
          26911.689453125,
          26967.396484375,
          27976.798828125,
          27508.251953125,
          27429.07421875,
          27798.646484375,
          27412.123046875,
          27946.78125,
          27971.677734375,
          27934.47265625,
          27589.201171875,
          27392.076171875,
          26873.29296875,
          26752.87890625,
          26866.203125,
          26858.01171875,
          27162.62890625,
          28522.09765625,
          28413.53125,
          28332.416015625,
          28732.8125,
          29683.380859375,
          29918.654296875,
          30140.685546875,
          33077.3046875,
          33916.04296875,
          34504.2890625,
          34156.5,
          33907.72265625,
          34089.37109375,
          34531.7421875,
          34500.078125,
          34657.2734375,
          35441.578125,
          34942.47265625,
          34736.32421875,
          35090.01171875,
          35044.7890625,
          35047.79296875,
          35419.4765625,
          35633.6328125,
          36702.25,
          37310.0703125,
          37133.9921875,
          37070.3046875,
          36491.7890625,
          35548.11328125,
          37879.98046875,
          36164.82421875,
          36625.37109375,
          36585.765625,
          37374.07421875,
          37469.16015625,
          35756.5546875,
          37420.43359375,
          37296.31640625,
          37721.4140625,
          37796.828125,
          37454.19140625,
          37247.9921875,
          37826.10546875,
          37861.1171875,
          37718.0078125,
          38689.27734375,
          39472.20703125,
          39978.62890625,
          41986.265625,
          44080.0234375,
          43769.1328125,
          43293.13671875,
          44180.01953125,
          43728.3828125,
          43792.01953125,
          41238.734375,
          41468.46484375,
          42884.26171875,
          43028.25,
          41937.7421875,
          42236.109375,
          41348.203125,
          42641.51171875,
          42261.30078125,
          43648.125,
          43868.98828125,
          44012.19921875,
          43728.3671875,
          43599.84765625
         ],
         "type": "candlestick",
         "x": [
          "2023-07-20T00:00:00+00:00",
          "2023-07-21T00:00:00+00:00",
          "2023-07-22T00:00:00+00:00",
          "2023-07-23T00:00:00+00:00",
          "2023-07-24T00:00:00+00:00",
          "2023-07-25T00:00:00+00:00",
          "2023-07-26T00:00:00+00:00",
          "2023-07-27T00:00:00+00:00",
          "2023-07-28T00:00:00+00:00",
          "2023-07-29T00:00:00+00:00",
          "2023-07-30T00:00:00+00:00",
          "2023-07-31T00:00:00+00:00",
          "2023-08-01T00:00:00+00:00",
          "2023-08-02T00:00:00+00:00",
          "2023-08-03T00:00:00+00:00",
          "2023-08-04T00:00:00+00:00",
          "2023-08-05T00:00:00+00:00",
          "2023-08-06T00:00:00+00:00",
          "2023-08-07T00:00:00+00:00",
          "2023-08-08T00:00:00+00:00",
          "2023-08-09T00:00:00+00:00",
          "2023-08-10T00:00:00+00:00",
          "2023-08-11T00:00:00+00:00",
          "2023-08-12T00:00:00+00:00",
          "2023-08-13T00:00:00+00:00",
          "2023-08-14T00:00:00+00:00",
          "2023-08-15T00:00:00+00:00",
          "2023-08-16T00:00:00+00:00",
          "2023-08-17T00:00:00+00:00",
          "2023-08-18T00:00:00+00:00",
          "2023-08-19T00:00:00+00:00",
          "2023-08-20T00:00:00+00:00",
          "2023-08-21T00:00:00+00:00",
          "2023-08-22T00:00:00+00:00",
          "2023-08-23T00:00:00+00:00",
          "2023-08-24T00:00:00+00:00",
          "2023-08-25T00:00:00+00:00",
          "2023-08-26T00:00:00+00:00",
          "2023-08-27T00:00:00+00:00",
          "2023-08-28T00:00:00+00:00",
          "2023-08-29T00:00:00+00:00",
          "2023-08-30T00:00:00+00:00",
          "2023-08-31T00:00:00+00:00",
          "2023-09-01T00:00:00+00:00",
          "2023-09-02T00:00:00+00:00",
          "2023-09-03T00:00:00+00:00",
          "2023-09-04T00:00:00+00:00",
          "2023-09-05T00:00:00+00:00",
          "2023-09-06T00:00:00+00:00",
          "2023-09-07T00:00:00+00:00",
          "2023-09-08T00:00:00+00:00",
          "2023-09-09T00:00:00+00:00",
          "2023-09-10T00:00:00+00:00",
          "2023-09-11T00:00:00+00:00",
          "2023-09-12T00:00:00+00:00",
          "2023-09-13T00:00:00+00:00",
          "2023-09-14T00:00:00+00:00",
          "2023-09-15T00:00:00+00:00",
          "2023-09-16T00:00:00+00:00",
          "2023-09-17T00:00:00+00:00",
          "2023-09-18T00:00:00+00:00",
          "2023-09-19T00:00:00+00:00",
          "2023-09-20T00:00:00+00:00",
          "2023-09-21T00:00:00+00:00",
          "2023-09-22T00:00:00+00:00",
          "2023-09-23T00:00:00+00:00",
          "2023-09-24T00:00:00+00:00",
          "2023-09-25T00:00:00+00:00",
          "2023-09-26T00:00:00+00:00",
          "2023-09-27T00:00:00+00:00",
          "2023-09-28T00:00:00+00:00",
          "2023-09-29T00:00:00+00:00",
          "2023-09-30T00:00:00+00:00",
          "2023-10-01T00:00:00+00:00",
          "2023-10-02T00:00:00+00:00",
          "2023-10-03T00:00:00+00:00",
          "2023-10-04T00:00:00+00:00",
          "2023-10-05T00:00:00+00:00",
          "2023-10-06T00:00:00+00:00",
          "2023-10-07T00:00:00+00:00",
          "2023-10-08T00:00:00+00:00",
          "2023-10-09T00:00:00+00:00",
          "2023-10-10T00:00:00+00:00",
          "2023-10-11T00:00:00+00:00",
          "2023-10-12T00:00:00+00:00",
          "2023-10-13T00:00:00+00:00",
          "2023-10-14T00:00:00+00:00",
          "2023-10-15T00:00:00+00:00",
          "2023-10-16T00:00:00+00:00",
          "2023-10-17T00:00:00+00:00",
          "2023-10-18T00:00:00+00:00",
          "2023-10-19T00:00:00+00:00",
          "2023-10-20T00:00:00+00:00",
          "2023-10-21T00:00:00+00:00",
          "2023-10-22T00:00:00+00:00",
          "2023-10-23T00:00:00+00:00",
          "2023-10-24T00:00:00+00:00",
          "2023-10-25T00:00:00+00:00",
          "2023-10-26T00:00:00+00:00",
          "2023-10-27T00:00:00+00:00",
          "2023-10-28T00:00:00+00:00",
          "2023-10-29T00:00:00+00:00",
          "2023-10-30T00:00:00+00:00",
          "2023-10-31T00:00:00+00:00",
          "2023-11-01T00:00:00+00:00",
          "2023-11-02T00:00:00+00:00",
          "2023-11-03T00:00:00+00:00",
          "2023-11-04T00:00:00+00:00",
          "2023-11-05T00:00:00+00:00",
          "2023-11-06T00:00:00+00:00",
          "2023-11-07T00:00:00+00:00",
          "2023-11-08T00:00:00+00:00",
          "2023-11-09T00:00:00+00:00",
          "2023-11-10T00:00:00+00:00",
          "2023-11-11T00:00:00+00:00",
          "2023-11-12T00:00:00+00:00",
          "2023-11-13T00:00:00+00:00",
          "2023-11-14T00:00:00+00:00",
          "2023-11-15T00:00:00+00:00",
          "2023-11-16T00:00:00+00:00",
          "2023-11-17T00:00:00+00:00",
          "2023-11-18T00:00:00+00:00",
          "2023-11-19T00:00:00+00:00",
          "2023-11-20T00:00:00+00:00",
          "2023-11-21T00:00:00+00:00",
          "2023-11-22T00:00:00+00:00",
          "2023-11-23T00:00:00+00:00",
          "2023-11-24T00:00:00+00:00",
          "2023-11-25T00:00:00+00:00",
          "2023-11-26T00:00:00+00:00",
          "2023-11-27T00:00:00+00:00",
          "2023-11-28T00:00:00+00:00",
          "2023-11-29T00:00:00+00:00",
          "2023-11-30T00:00:00+00:00",
          "2023-12-01T00:00:00+00:00",
          "2023-12-02T00:00:00+00:00",
          "2023-12-03T00:00:00+00:00",
          "2023-12-04T00:00:00+00:00",
          "2023-12-05T00:00:00+00:00",
          "2023-12-06T00:00:00+00:00",
          "2023-12-07T00:00:00+00:00",
          "2023-12-08T00:00:00+00:00",
          "2023-12-09T00:00:00+00:00",
          "2023-12-10T00:00:00+00:00",
          "2023-12-11T00:00:00+00:00",
          "2023-12-12T00:00:00+00:00",
          "2023-12-13T00:00:00+00:00",
          "2023-12-14T00:00:00+00:00",
          "2023-12-15T00:00:00+00:00",
          "2023-12-16T00:00:00+00:00",
          "2023-12-17T00:00:00+00:00",
          "2023-12-18T00:00:00+00:00",
          "2023-12-19T00:00:00+00:00",
          "2023-12-20T00:00:00+00:00",
          "2023-12-21T00:00:00+00:00",
          "2023-12-22T00:00:00+00:00",
          "2023-12-23T00:00:00+00:00",
          "2023-12-24T00:00:00+00:00",
          "2023-12-26T00:00:00+00:00"
         ]
        },
        {
         "line": {
          "color": "blue"
         },
         "name": "Predicted Price",
         "type": "scatter",
         "x": [
          "2023-08-19T00:00:00+00:00",
          "2023-08-20T00:00:00+00:00",
          "2023-08-21T00:00:00+00:00",
          "2023-08-22T00:00:00+00:00",
          "2023-08-23T00:00:00+00:00",
          "2023-08-24T00:00:00+00:00",
          "2023-08-25T00:00:00+00:00",
          "2023-08-26T00:00:00+00:00",
          "2023-08-27T00:00:00+00:00",
          "2023-08-28T00:00:00+00:00",
          "2023-08-29T00:00:00+00:00",
          "2023-08-30T00:00:00+00:00",
          "2023-08-31T00:00:00+00:00",
          "2023-09-01T00:00:00+00:00",
          "2023-09-02T00:00:00+00:00",
          "2023-09-03T00:00:00+00:00",
          "2023-09-04T00:00:00+00:00",
          "2023-09-05T00:00:00+00:00",
          "2023-09-06T00:00:00+00:00",
          "2023-09-07T00:00:00+00:00",
          "2023-09-08T00:00:00+00:00",
          "2023-09-09T00:00:00+00:00",
          "2023-09-10T00:00:00+00:00",
          "2023-09-11T00:00:00+00:00",
          "2023-09-12T00:00:00+00:00",
          "2023-09-13T00:00:00+00:00",
          "2023-09-14T00:00:00+00:00",
          "2023-09-15T00:00:00+00:00",
          "2023-09-16T00:00:00+00:00",
          "2023-09-17T00:00:00+00:00",
          "2023-09-18T00:00:00+00:00",
          "2023-09-19T00:00:00+00:00",
          "2023-09-20T00:00:00+00:00",
          "2023-09-21T00:00:00+00:00",
          "2023-09-22T00:00:00+00:00",
          "2023-09-23T00:00:00+00:00",
          "2023-09-24T00:00:00+00:00",
          "2023-09-25T00:00:00+00:00",
          "2023-09-26T00:00:00+00:00",
          "2023-09-27T00:00:00+00:00",
          "2023-09-28T00:00:00+00:00",
          "2023-09-29T00:00:00+00:00",
          "2023-09-30T00:00:00+00:00",
          "2023-10-01T00:00:00+00:00",
          "2023-10-02T00:00:00+00:00",
          "2023-10-03T00:00:00+00:00",
          "2023-10-04T00:00:00+00:00",
          "2023-10-05T00:00:00+00:00",
          "2023-10-06T00:00:00+00:00",
          "2023-10-07T00:00:00+00:00",
          "2023-10-08T00:00:00+00:00",
          "2023-10-09T00:00:00+00:00",
          "2023-10-10T00:00:00+00:00",
          "2023-10-11T00:00:00+00:00",
          "2023-10-12T00:00:00+00:00",
          "2023-10-13T00:00:00+00:00",
          "2023-10-14T00:00:00+00:00",
          "2023-10-15T00:00:00+00:00",
          "2023-10-16T00:00:00+00:00",
          "2023-10-17T00:00:00+00:00",
          "2023-10-18T00:00:00+00:00",
          "2023-10-19T00:00:00+00:00",
          "2023-10-20T00:00:00+00:00",
          "2023-10-21T00:00:00+00:00",
          "2023-10-22T00:00:00+00:00",
          "2023-10-23T00:00:00+00:00",
          "2023-10-24T00:00:00+00:00",
          "2023-10-25T00:00:00+00:00",
          "2023-10-26T00:00:00+00:00",
          "2023-10-27T00:00:00+00:00",
          "2023-10-28T00:00:00+00:00",
          "2023-10-29T00:00:00+00:00",
          "2023-10-30T00:00:00+00:00",
          "2023-10-31T00:00:00+00:00",
          "2023-11-01T00:00:00+00:00",
          "2023-11-02T00:00:00+00:00",
          "2023-11-03T00:00:00+00:00",
          "2023-11-04T00:00:00+00:00",
          "2023-11-05T00:00:00+00:00",
          "2023-11-06T00:00:00+00:00",
          "2023-11-07T00:00:00+00:00",
          "2023-11-08T00:00:00+00:00",
          "2023-11-09T00:00:00+00:00",
          "2023-11-10T00:00:00+00:00",
          "2023-11-11T00:00:00+00:00",
          "2023-11-12T00:00:00+00:00",
          "2023-11-13T00:00:00+00:00",
          "2023-11-14T00:00:00+00:00",
          "2023-11-15T00:00:00+00:00",
          "2023-11-16T00:00:00+00:00",
          "2023-11-17T00:00:00+00:00",
          "2023-11-18T00:00:00+00:00",
          "2023-11-19T00:00:00+00:00",
          "2023-11-20T00:00:00+00:00",
          "2023-11-21T00:00:00+00:00",
          "2023-11-22T00:00:00+00:00",
          "2023-11-23T00:00:00+00:00",
          "2023-11-24T00:00:00+00:00",
          "2023-11-25T00:00:00+00:00",
          "2023-11-26T00:00:00+00:00",
          "2023-11-27T00:00:00+00:00",
          "2023-11-28T00:00:00+00:00",
          "2023-11-29T00:00:00+00:00",
          "2023-11-30T00:00:00+00:00",
          "2023-12-01T00:00:00+00:00",
          "2023-12-02T00:00:00+00:00",
          "2023-12-03T00:00:00+00:00",
          "2023-12-04T00:00:00+00:00",
          "2023-12-05T00:00:00+00:00",
          "2023-12-06T00:00:00+00:00",
          "2023-12-07T00:00:00+00:00",
          "2023-12-08T00:00:00+00:00",
          "2023-12-09T00:00:00+00:00",
          "2023-12-10T00:00:00+00:00",
          "2023-12-11T00:00:00+00:00",
          "2023-12-12T00:00:00+00:00",
          "2023-12-13T00:00:00+00:00",
          "2023-12-14T00:00:00+00:00",
          "2023-12-15T00:00:00+00:00",
          "2023-12-16T00:00:00+00:00",
          "2023-12-17T00:00:00+00:00",
          "2023-12-18T00:00:00+00:00",
          "2023-12-19T00:00:00+00:00",
          "2023-12-20T00:00:00+00:00",
          "2023-12-21T00:00:00+00:00",
          "2023-12-22T00:00:00+00:00",
          "2023-12-23T00:00:00+00:00",
          "2023-12-24T00:00:00+00:00",
          "2023-12-26T00:00:00+00:00"
         ],
         "y": [
          37978.48024123907,
          34401.4597327793,
          34521.020012845285,
          34384.14653135184,
          34720.658358159475,
          33678.7598152766,
          33732.7643795209,
          33880.54878483061,
          33717.07203640416,
          33840.89749578014,
          33884.35182790458,
          33793.42370556388,
          33738.666197403334,
          34284.92475431692,
          33658.95558682084,
          33673.46441030875,
          33559.20404385682,
          33522.62990584131,
          33516.64242368098,
          33679.97038678266,
          34357.119451675564,
          34123.13423957117,
          33962.61741737835,
          33933.62907660287,
          33953.02752690017,
          33799.1361603057,
          33943.16486332659,
          33667.33716011606,
          33125.69771123957,
          30743.71905437857,
          30064.75751371123,
          30121.347786554135,
          30227.339295865968,
          30160.460292383097,
          30056.265478583984,
          30507.614778557792,
          30198.47043421492,
          30064.067690841854,
          30019.06238442287,
          30112.984247843735,
          30127.840237089433,
          32001.81845440995,
          31512.253869201988,
          29933.39585220348,
          29779.756969796494,
          29858.89272798784,
          29972.810437328182,
          29795.970061549917,
          29760.160139066167,
          29719.048048645258,
          30292.57264348399,
          29900.390307659283,
          29888.60019783303,
          29815.312153769657,
          29040.769567877986,
          29822.052579846233,
          30273.029916508123,
          30625.689459699206,
          30709.232419556007,
          30665.058958361857,
          30624.738135349937,
          30887.73423146084,
          31406.411145214923,
          31313.625460637733,
          30660.590889972635,
          30677.326984685846,
          30678.269291742705,
          30302.460104611702,
          30349.76256627217,
          30251.35459987726,
          30420.232706457376,
          31192.435304968618,
          31061.833350346424,
          31126.131153876893,
          32291.196893789805,
          31750.393798784353,
          31659.005794530734,
          32085.571066315286,
          31639.440524323843,
          32256.550202026963,
          32285.28605861496,
          32242.343457834795,
          31843.82647409197,
          31616.302151999436,
          31017.51561247371,
          30878.532084556296,
          31009.332419611514,
          30999.877788519487,
          31351.47103688307,
          32920.58812375553,
          32795.279319778085,
          32701.655027006753,
          33163.79802599549,
          34260.95679109078,
          34532.512552022,
          34788.78400231805,
          38178.269248809665,
          39146.35223602317,
          39825.31377669051,
          39423.89097046852,
          39136.74881960638,
          39346.409885434434,
          39857.00054221973,
          39820.45345608145,
          40001.89039666578,
          40907.14539901167,
          40331.071164743975,
          40093.131869917735,
          40501.36273190938,
          40449.16613479331,
          40452.63328372501,
          40881.6354787834,
          41128.81749833003,
          42362.22980606556,
          43063.78417286649,
          42860.552436526865,
          42787.04346879944,
          42119.312965828925,
          41030.10970696248,
          43721.582128247246,
          41741.92575252615,
          42273.49514010362,
          42227.78197623044,
          43137.65834093653,
          43247.40780686028,
          41270.695577111095,
          43191.16695409827,
          43047.90922957845,
          43538.57164633088
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "BTC-USD price predictions",
         "x": 0.3
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "df = prices_df_val.iloc[200:]\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "        go.Candlestick(\n",
    "            x=df['Date'],\n",
    "            open=df['Open'],\n",
    "            high=df['High'],\n",
    "            low=df['Low'],\n",
    "            close=df['Close'],\n",
    "            name='Actual Price'\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=date,\n",
    "            y=predict_out,\n",
    "            line=dict(color='blue'),\n",
    "            name='Predicted Price'\n",
    "            )\n",
    "    ]).update_layout(title_text=tickers+' price predictions', title_x=0.3)\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
